{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Assignment 1**\n",
    "Javiera de la Carrera - 13743354"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#import spark libraries\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, IntegerType, FloatType\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import to_timestamp,date_format,hour,dayofweek,quarter\n",
    "from pyspark.sql.functions import col,max, min, sum\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "#modeling part\n",
    "from pyspark.mllib.stat import Statistics\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "#import python libraries\n",
    "import glob\n",
    "import pandas as pd\n",
    "# import numpy as np\n",
    "# import statsmodels\n",
    "\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docker\n",
    "spark = SparkSession.builder \\\n",
    "        .appName('taxis') \\\n",
    "        .config('spark.sql.shuffle.partitions', 1000) \\\n",
    "        .config('spark.sql.repl.eagerEval.enabled',True) \\\n",
    "        .config(\"spark.driver.memory\", \"12g\")\\\n",
    "        .config(\"spark.sql.autoBroadcastJoinThreshold\",-1)\\\n",
    "        .getOrCreate() \n",
    "        \n",
    "#.config(\"spark.sql.broadcastTimeout\", 36000)\\    \n",
    "#df.rdd.getNumPartitions() #to be used in the middle for partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment below to create Spark Session in GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GCP\n",
    "\n",
    "### Initialise Spark session\n",
    "\n",
    "## Builder\n",
    "# spark = SparkSession.builder \\\n",
    "#                     .appName('taxi') \\\n",
    "#                     .config('spark.jars.packages', 'com.google.cloud.spark:spark-bigquery-with-dependencies_2.11:0.17.1') \\\n",
    "#                     .getOrCreate()\n",
    "\n",
    "# ## To always show the results of DataFrames and improve the formatting of the output, Spark DataFrame into Pandas DataFrame\n",
    "# spark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.sql.repl.eagerEval.enabled', 'True'),\n",
       " ('spark.sql.shuffle.partitions', '1000'),\n",
       " ('spark.driver.memory', '12g'),\n",
       " ('spark.driver.extraJavaOptions',\n",
       "  '\"-Dio.netty.tryReflectionSetAccessible=true\"'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.name', 'taxis'),\n",
       " ('spark.executor.extraJavaOptions',\n",
       "  '\"-Dio.netty.tryReflectionSetAccessible=true\"'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.sql.autoBroadcastJoinThreshold', '-1'),\n",
       " ('spark.driver.host', 'd96dce464e23'),\n",
       " ('spark.driver.port', '40611'),\n",
       " ('spark.app.id', 'local-1618213207967'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.debug.maxToStringFields', '1000')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext._conf.getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading the data: 2019-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all the taxis files: PLEASE CHANGE THE PATH TO YOUR FOLDER\n",
    "\n",
    "txtfiles_gt = [file for file in glob.glob(\"*green_tripdata*.csv\")]\n",
    "txtfiles_yt = [file for file in glob.glob(\"*yellow_tripdata*.csv\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read one csv of each type of taxi to know about the data inside them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: string (nullable = true)\n",
      " |-- lpep_pickup_datetime: string (nullable = true)\n",
      " |-- lpep_dropoff_datetime: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- passenger_count: string (nullable = true)\n",
      " |-- trip_distance: string (nullable = true)\n",
      " |-- fare_amount: string (nullable = true)\n",
      " |-- extra: string (nullable = true)\n",
      " |-- mta_tax: string (nullable = true)\n",
      " |-- tip_amount: string (nullable = true)\n",
      " |-- tolls_amount: string (nullable = true)\n",
      " |-- ehail_fee: string (nullable = true)\n",
      " |-- improvement_surcharge: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- trip_type: string (nullable = true)\n",
      " |-- congestion_surcharge: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#open one csv for green and look the columns\n",
    "spark.read.csv(\"green_tripdata_2019-01.csv\",header=True).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: string (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: string (nullable = true)\n",
      " |-- trip_distance: string (nullable = true)\n",
      " |-- RatecodeID: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- fare_amount: string (nullable = true)\n",
      " |-- extra: string (nullable = true)\n",
      " |-- mta_tax: string (nullable = true)\n",
      " |-- tip_amount: string (nullable = true)\n",
      " |-- tolls_amount: string (nullable = true)\n",
      " |-- improvement_surcharge: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      " |-- congestion_surcharge: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#open one csv for yellow and look the column\n",
    "spark.read.csv(\"yellow_tripdata_2019-01.csv\",header=True).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After read the Schemas we could realise that the variables of yellow taxis data are almost the same as for green taxis. However, green taxis have 2 more variables. Therefore, they will be loaded separatedly and for the yellow ones, trip_type and ehail_fee will be created.\n",
    "\n",
    "Also, a schema for each type of data will be created because it is useful to have a faster download. With that Spark does not have to understand the format of the data (it does not have to create the Schema by itself). \n",
    "\n",
    "In summary, because of this two conditions, it is handy to create the Schema by ourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the Schemas were created using the data dictionary trip records\n",
    "#green\n",
    "green_schema = StructType(\n",
    "    [StructField(\"VendorID\", StringType(), False),\n",
    "     StructField(\"pickup_datetime\", TimestampType(), False),\n",
    "     StructField(\"dropoff_datetime\", TimestampType(), False),\n",
    "     StructField(\"store_and_fwd_flag\", StringType(), False),\n",
    "     StructField(\"RatecodeID\", StringType(), False),\n",
    "     StructField(\"PULocationID\", StringType(), False), #pick up location id\n",
    "     StructField(\"DOLocationID\", StringType(), False), #drop off location id\n",
    "     StructField(\"passenger_count\", IntegerType(), False),\n",
    "     StructField(\"trip_distance\", FloatType(), False), #milles\n",
    "     StructField(\"fare_amount\", FloatType(), False),\n",
    "     StructField(\"extra\", FloatType(), False),\n",
    "     StructField(\"mta_tax\", FloatType(), False),\n",
    "     StructField(\"tip_amount\", FloatType(), False),\n",
    "     StructField(\"tolls_amount\", FloatType(), False),\n",
    "     StructField(\"ehail_fee\", FloatType(), False),\n",
    "     StructField(\"improvement_surcharge\", FloatType(), False),\n",
    "     StructField(\"total_amount\", FloatType(), False),\n",
    "     StructField(\"payment_type\", StringType(), False),\n",
    "     StructField(\"trip_type\", StringType(), False),\n",
    "     StructField(\"congestion_surcharge\", FloatType(), False)])\n",
    "\n",
    "\n",
    "#yellow\n",
    "\n",
    "yellow_schema = StructType(\n",
    "    [StructField(\"VendorID\", StringType(), False),\n",
    "     StructField(\"pickup_datetime\", TimestampType(), False),\n",
    "     StructField(\"dropoff_datetime\", TimestampType(), False),\n",
    "     StructField(\"passenger_count\", IntegerType(), False),\n",
    "     StructField(\"trip_distance\", FloatType(), False),\n",
    "     StructField(\"RatecodeID\", StringType(), False),\n",
    "     StructField(\"store_and_fwd_flag\", StringType(), False),\n",
    "     StructField(\"PULocationID\", StringType(), False),\n",
    "     StructField(\"DOLocationID\", StringType(), False),\n",
    "     StructField(\"payment_type\", StringType(), False),\n",
    "     StructField(\"fare_amount\", FloatType(), False),\n",
    "     StructField(\"extra\", FloatType(), False),\n",
    "     StructField(\"mta_tax\", FloatType(), False),\n",
    "     StructField(\"tip_amount\", FloatType(), False),\n",
    "     StructField(\"tolls_amount\", FloatType(), False),\n",
    "     StructField(\"improvement_surcharge\", FloatType(), False),\n",
    "     StructField(\"total_amount\", FloatType(), False),\n",
    "     StructField(\"congestion_surcharge\", FloatType(), False),\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading yellow csv\n",
    "\n",
    "yellow = spark.read.option(\"header\",True) \\\n",
    "    .schema(yellow_schema) \\\n",
    "    .csv(txtfiles_yt) \\\n",
    "    .withColumn(\"taxi_type\", lit(\"yellow\").cast(StringType())) \\\n",
    "    .withColumn(\"ehail_fee\", lit(0.0).cast(FloatType())) \\\n",
    "    .withColumn(\"trip_type\", lit(\"no\").cast(StringType()))\n",
    "\n",
    "#lit to put in all rows the value defined \n",
    "#trip type: I put another value, not nan because the green taxis have nan\n",
    "#taxi_type: new variable to know if is a yellow or green taxi\n",
    "#ehail_fee: new variable from green without a description in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading green csv\n",
    "\n",
    "green = spark.read.option(\"header\",True)\\\n",
    "    .schema(green_schema) \\\n",
    "    .csv(txtfiles_gt)\\\n",
    "    .withColumn(\"taxi_type\", lit(\"green\").cast(StringType()))\n",
    "\n",
    "# only new variable to know if is a yellow or green taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder green variables to merge with yellow ones. They need the same Schema to be merged.\n",
    "\n",
    "green = green.select(['VendorID',\n",
    " 'pickup_datetime',\n",
    " 'dropoff_datetime',\n",
    " 'passenger_count',\n",
    " 'trip_distance',\n",
    " 'RatecodeID',\n",
    " 'store_and_fwd_flag',\n",
    " 'PULocationID',\n",
    " 'DOLocationID',\n",
    " 'payment_type',\n",
    " 'fare_amount',\n",
    " 'extra',\n",
    " 'mta_tax',\n",
    " 'tip_amount',\n",
    " 'tolls_amount',\n",
    " 'improvement_surcharge',\n",
    " 'total_amount',\n",
    " 'congestion_surcharge',\n",
    " 'taxi_type',\n",
    " 'ehail_fee',\n",
    " 'trip_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge both data\n",
    "df = yellow.union(green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: float (nullable = true)\n",
      " |-- RatecodeID: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- fare_amount: float (nullable = true)\n",
      " |-- extra: float (nullable = true)\n",
      " |-- mta_tax: float (nullable = true)\n",
      " |-- tip_amount: float (nullable = true)\n",
      " |-- tolls_amount: float (nullable = true)\n",
      " |-- improvement_surcharge: float (nullable = true)\n",
      " |-- total_amount: float (nullable = true)\n",
      " |-- congestion_surcharge: float (nullable = true)\n",
      " |-- taxi_type: string (nullable = false)\n",
      " |-- ehail_fee: float (nullable = true)\n",
      " |-- trip_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#final Schema\n",
    "\n",
    "df.printSchema()\n",
    "#all variables that are codes, categorical or ID were transformed to string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploring and cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows columns\n",
      "(116825619, 21)\n"
     ]
    }
   ],
   "source": [
    "#number the rows and columns\n",
    "count = df.count()\n",
    "print(\"rows\",\"columns\")\n",
    "print((count, len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'RatecodeID',\n",
       " 'store_and_fwd_flag',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'congestion_surcharge',\n",
       " 'taxi_type',\n",
       " 'ehail_fee',\n",
       " 'trip_type']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(VendorID='1', pickup_datetime=datetime.datetime(2019, 1, 1, 0, 46, 40), dropoff_datetime=datetime.datetime(2019, 1, 1, 0, 53, 20), passenger_count=1, trip_distance=1.5, RatecodeID='1', store_and_fwd_flag='N', PULocationID='151', DOLocationID='239', payment_type='1', fare_amount=7.0, extra=0.5, mta_tax=0.5, tip_amount=1.649999976158142, tolls_amount=0.0, improvement_surcharge=0.30000001192092896, total_amount=9.949999809265137, congestion_surcharge=None, taxi_type='yellow', ehail_fee=0.0, trip_type='no')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one row\n",
    "#In each trip record dataset, one row represents a single trip.\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>pickup_datetime</th><th>dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>taxi_type</th><th>ehail_fee</th><th>trip_type</th></tr>\n",
       "<tr><td>1998368</td><td>0</td><td>0</td><td>1998368</td><td>0</td><td>1998368</td><td>1998368</td><td>0</td><td>0</td><td>1998368</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>6344562</td><td>0</td><td>7777747</td><td>942563</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+---------+\n",
       "|VendorID|pickup_datetime|dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|taxi_type|ehail_fee|trip_type|\n",
       "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+---------+\n",
       "| 1998368|              0|               0|        1998368|            0|   1998368|           1998368|           0|           0|     1998368|          0|    0|      0|         0|           0|                    2|           0|             6344562|        0|  7777747|   942563|\n",
       "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+---------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns))\n",
    "#df.select([F.round((F.count(F.when(F.isnull(F.col(c).cast(\"int\")), F.col(c).cast(\"int\")))/count),6).alias(c) for c in df.columns])\n",
    "\n",
    "#missing values for string passed to integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|   passenger_count|\n",
      "+-------+------------------+\n",
      "|  count|         114827251|\n",
      "|   mean|1.5277970209353875|\n",
      "| stddev|1.1775814890423952|\n",
      "|    min|                 0|\n",
      "|    max|                 9|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|       fare_amount|\n",
      "+-------+------------------+\n",
      "|  count|         116825619|\n",
      "|   mean|13.311462728042809|\n",
      "| stddev| 194.4980192640717|\n",
      "|    min|           -1856.0|\n",
      "|    max|          998310.0|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|             extra|\n",
      "+-------+------------------+\n",
      "|  count|         116825619|\n",
      "|   mean|1.0469919483353511|\n",
      "| stddev|  46.2759172156658|\n",
      "|    min|             -60.0|\n",
      "|    max|          500000.8|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|     trip_distance|\n",
      "+-------+------------------+\n",
      "|  count|         116825619|\n",
      "|   mean|3.3396968832882794|\n",
      "| stddev|209.06998305117406|\n",
      "|    min|         -37264.53|\n",
      "|    max|         350914.88|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+-------------------+\n",
      "|summary|            mta_tax|\n",
      "+-------+-------------------+\n",
      "|  count|          116825619|\n",
      "|   mean|0.49565033650707385|\n",
      "| stddev| 46.259569466555284|\n",
      "|    min|               -0.5|\n",
      "|    max|           500000.5|\n",
      "+-------+-------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|        tip_amount|\n",
      "+-------+------------------+\n",
      "|  count|         116825619|\n",
      "|   mean|2.0947549758564086|\n",
      "| stddev|13.375502229783272|\n",
      "|    min|           -493.22|\n",
      "|    max|         141492.02|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|      total_amount|\n",
      "+-------+------------------+\n",
      "|  count|         116825619|\n",
      "|   mean|18.895122402629656|\n",
      "| stddev|221.17702763633338|\n",
      "|    min|           -1871.8|\n",
      "|    max|         1084772.1|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+--------------------+\n",
      "|summary|           ehail_fee|\n",
      "+-------+--------------------+\n",
      "|  count|           109047872|\n",
      "|   mean|5.364616508106777E-8|\n",
      "| stddev|3.234347268731717E-4|\n",
      "|    min|                 0.0|\n",
      "|    max|                1.95|\n",
      "+-------+--------------------+\n",
      "\n",
      "+-------+---------------------+\n",
      "|summary|improvement_surcharge|\n",
      "+-------+---------------------+\n",
      "|  count|            116825617|\n",
      "|   mean|  0.29677402840246264|\n",
      "| stddev| 0.037349296637125454|\n",
      "|    min|                 -0.3|\n",
      "|    max|                  1.0|\n",
      "+-------+---------------------+\n",
      "\n",
      "+-------+-------------------+\n",
      "|summary|       tolls_amount|\n",
      "+-------+-------------------+\n",
      "|  count|          116825619|\n",
      "|   mean|0.35989980738236227|\n",
      "| stddev| 1.7515866650268808|\n",
      "|    min|              -70.0|\n",
      "|    max|             3288.0|\n",
      "+-------+-------------------+\n",
      "\n",
      "+-------+--------------------+\n",
      "|summary|congestion_surcharge|\n",
      "+-------+--------------------+\n",
      "|  count|           110481057|\n",
      "|   mean|  2.0925866952015135|\n",
      "| stddev|  0.9382563169971059|\n",
      "|    min|               -2.75|\n",
      "|    max|                 4.5|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#first looking of the variables \n",
    "df.describe(\"passenger_count\").show() \n",
    "df.describe(\"fare_amount\").show() \n",
    "df.describe(\"extra\").show() \n",
    "df.describe(\"trip_distance\").show() \n",
    "df.describe(\"mta_tax\").show()\n",
    "df.describe(\"tip_amount\").show()\n",
    "df.describe(\"total_amount\").show()\n",
    "df.describe(\"ehail_fee\").show()\n",
    "df.describe(\"improvement_surcharge\").show()\n",
    "df.describe(\"tolls_amount\").show()\n",
    "df.describe(\"congestion_surcharge\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First cleaning using the definitions of [NYC taxi fare webpage ](https://www1.nyc.gov/site/tlc/passengers/taxi-fare.page#:~:text=%242.50%20initial%20charge.,Dutchess%2C%20Orange%20or%20Putnam%20Counties.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter all variables with negative values--> assumption: we have much data, so we can dropped it \n",
    "#with less data it could be better to replace\n",
    "#ehail fee do not look bad but it is only for green in the dataset\n",
    "\n",
    "#payments\n",
    "df = df.where((F.col(\"fare_amount\")>= 2.50)) # $2.50 initial charge and max of 2.50 + 0.50*1/5*tripdistance\n",
    "df = df.where((F.col(\"mta_tax\")>= 0)) # 0.5 for some destinations\n",
    "df = df.where((F.col(\"tip_amount\")>=0) & (F.col(\"total_amount\")>= 2.50)) # it was assumed that an uncharged payment has a total amount\n",
    "df = df.where((F.col(\"tolls_amount\")>=0) & (F.col(\"extra\")>= 0) & (F.col(\"extra\")<= 1.00)) #overnight 0.5 and rush max 1.00 as extras\n",
    "df = df.where((F.col(\"congestion_surcharge\")>=0) & (F.col(\"congestion_surcharge\")<= 2.75)) #congestion max 2.75\n",
    "              \n",
    "#passengers:maxium of 6 passenger (4 for small car and 6 for big)         \n",
    "df = df.where((F.col(\"passenger_count\")>0) & (F.col(\"passenger_count\")<7)) \n",
    "\n",
    "\n",
    "#no negative distance\n",
    "df = df.where((F.col(\"trip_distance\")>= 0)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|   passenger_count|\n",
      "+-------+------------------+\n",
      "|  count|          75927602|\n",
      "|   mean|1.6606915888111415|\n",
      "| stddev|1.3071586084115319|\n",
      "|    min|                 1|\n",
      "|    max|                 6|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|       fare_amount|\n",
      "+-------+------------------+\n",
      "|  count|          75927602|\n",
      "|   mean|13.355921415944218|\n",
      "| stddev|103.78408539441818|\n",
      "|    min|               2.5|\n",
      "|    max|          671123.1|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+-------------------+\n",
      "|summary|              extra|\n",
      "+-------+-------------------+\n",
      "|  count|           75927602|\n",
      "|   mean|0.31109860298337483|\n",
      "| stddev|  0.380063858124019|\n",
      "|    min|                0.0|\n",
      "|    max|                1.0|\n",
      "+-------+-------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|     trip_distance|\n",
      "+-------+------------------+\n",
      "|  count|          75927602|\n",
      "|   mean|3.0256178133698484|\n",
      "| stddev| 32.21392288199482|\n",
      "|    min|               0.0|\n",
      "|    max|         167329.45|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+--------------------+\n",
      "|summary|             mta_tax|\n",
      "+-------+--------------------+\n",
      "|  count|            75927602|\n",
      "|   mean|  0.4956669038487164|\n",
      "| stddev|0.046475987251246575|\n",
      "|    min|                 0.0|\n",
      "|    max|               17.33|\n",
      "+-------+--------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|        tip_amount|\n",
      "+-------+------------------+\n",
      "|  count|          75927602|\n",
      "|   mean|2.1141897375584633|\n",
      "| stddev|2.8235389120612466|\n",
      "|    min|               0.0|\n",
      "|    max|           1393.56|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|      total_amount|\n",
      "+-------+------------------+\n",
      "|  count|          75927602|\n",
      "|   mean| 18.90620017089943|\n",
      "| stddev|104.12033724390177|\n",
      "|    min|               2.5|\n",
      "|    max|         671124.94|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+--------------------+\n",
      "|summary|           ehail_fee|\n",
      "+-------+--------------------+\n",
      "|  count|            69836566|\n",
      "|   mean|8.376700743062234E-8|\n",
      "| stddev| 4.04160443148627E-4|\n",
      "|    min|                 0.0|\n",
      "|    max|                1.95|\n",
      "+-------+--------------------+\n",
      "\n",
      "+-------+---------------------+\n",
      "|summary|improvement_surcharge|\n",
      "+-------+---------------------+\n",
      "|  count|             75927602|\n",
      "|   mean|  0.29906105295270274|\n",
      "| stddev| 0.016762601783182944|\n",
      "|    min|                  0.0|\n",
      "|    max|                  1.0|\n",
      "+-------+---------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|      tolls_amount|\n",
      "+-------+------------------+\n",
      "|  count|          75927602|\n",
      "|   mean|0.3554707017431552|\n",
      "| stddev|1.6848993772192231|\n",
      "|    min|               0.0|\n",
      "|    max|             912.5|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+--------------------+\n",
      "|summary|congestion_surcharge|\n",
      "+-------+--------------------+\n",
      "|  count|            75927602|\n",
      "|   mean|  1.9670440777255158|\n",
      "| stddev|  1.0274231521935984|\n",
      "|    min|                 0.0|\n",
      "|    max|                2.75|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#describe again to know the new measures\n",
    "\n",
    "df.describe(\"passenger_count\").show() \n",
    "df.describe(\"fare_amount\").show() \n",
    "df.describe(\"extra\").show() \n",
    "df.describe(\"trip_distance\").show() \n",
    "df.describe(\"mta_tax\").show()\n",
    "df.describe(\"tip_amount\").show()\n",
    "df.describe(\"total_amount\").show()\n",
    "df.describe(\"ehail_fee\").show()\n",
    "df.describe(\"improvement_surcharge\").show()\n",
    "df.describe(\"tolls_amount\").show()\n",
    "df.describe(\"congestion_surcharge\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Cleaning\n",
    "\n",
    "We do not know what is the max of each variable. Therefore, considering the Central Limit Theorem I can assume a normal distribution for the numeric variables because we are using a large dataset. Therefore, the definition mentions by  [machine lr mastery](https://machinelearningmastery.com/how-to-use-statistics-to-identify-outliers-in-data/) was used: Outliers are defined as any point located further than 3 standard deviations from the mean. Sometimes I used 4 st deviation because it was more logical. Also, some of them where looked with more detailed. For example: for distance is reasonable looking the map of the boroughs. mta is assumed to be 0 or 0,5 (categorical) as [NYC mta](https://www.tax.ny.gov/bus/mctmt/taxi.htm#:~:text=The%20taxicab%20and%20hail%20vehicle%20trip%20tax%20in%20the%20Metropolitan,and%20Bronx%20counties) said. For payment type = no charge it was assumed 0 payment but with a total amount value, so I did not take out.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691347"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some outliers \n",
    "#if the fare in more than the minimun and distance = 0\n",
    "df.where((F.col(\"total_amount\")> 6.50) & (F.col(\"trip_distance\")==0)).count() \n",
    "\n",
    "#max total amount: fare + extras + congestion + improv =  6.55\n",
    "#https://www1.nyc.gov/site/tlc/passengers/taxi-fare.page#:~:text=%242.50%20initial%20charge.,Dutchess%2C%20Orange%20or%20Putnam%20Counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17569"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if the fare is more than the minimun and distance = 0\n",
    "df.where((F.col(\"fare_amount\")== 2.50) & (F.col(\"trip_distance\")> 0.2)).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take out outliers for fare amount, total amount and distance\n",
    "df = df.where((F.col(\"fare_amount\")< 350)) # aprox 3 st deviation \n",
    "df = df.where((F.col(\"total_amount\")< 400)) # aprox 3 st deviation but a little bigger than fare amount\n",
    "df = df.where((F.col(\"tolls_amount\")< 10)) # aprox 3 std deviation \n",
    "df = df.where((F.col(\"fare_amount\")) <= (F.col(\"total_amount\")))\n",
    "\n",
    "## Also, the maximun distance in a straigh line is 50 milles in google maps, however, here is like 100 becaue we do not know if the drivers makes circles.\n",
    "df = df.where((F.col(\"trip_distance\")< 100 )) #3 st deviation\n",
    "\n",
    "#because the st dev is very small because cash payments has 0 tips, I will put a maximun of 100\n",
    "df = df.where((F.col(\"tip_amount\")) < 100)\n",
    "\n",
    "#combination fares and distance in a logical form\n",
    "df = df.where((F.col(\"fare_amount\")> 2.50) & (F.col(\"trip_distance\")!=0) | (F.col(\"total_amount\")<= 6.50) & (F.col(\"trip_distance\")==0))\n",
    "\n",
    "\n",
    "#mta tax is 0 or 0,5: changes to categorical\n",
    "#The taxicab and hail vehicle trip tax in the Metropolitan Commuter Transportation District is a tax of $0.50 per taxicab and hail vehicle trip in some ocassions.\n",
    "\n",
    "df = df.withColumn(\"mta_tax\", \\\n",
    "              when(df[\"mta_tax\"] > 0 , 0.5).otherwise(df[\"mta_tax\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|     total_amount|\n",
      "+-------+-----------------+\n",
      "|  count|         74769315|\n",
      "|   mean|18.35019022706662|\n",
      "| stddev|13.23944152682991|\n",
      "|    min|              2.5|\n",
      "|    max|           399.68|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#st devation of total amount, necesary to the model performance\n",
    "df.describe(\"total_amount\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables\n",
    "- looking the balance and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>count</th></tr>\n",
       "<tr><td>1</td><td>4208739</td></tr>\n",
       "<tr><td>4</td><td>196257</td></tr>\n",
       "<tr><td>2</td><td>70364319</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------+\n",
       "|VendorID|   count|\n",
       "+--------+--------+\n",
       "|       1| 4208739|\n",
       "|       4|  196257|\n",
       "|       2|70364319|\n",
       "+--------+--------+"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VendorID: to types of machine\n",
    "df.groupBy(\"VendorID\").count()\n",
    "#4 is weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>store_and_fwd_flag</th><th>count</th></tr>\n",
       "<tr><td>Y</td><td>122061</td></tr>\n",
       "<tr><td>N</td><td>74647254</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------------+--------+\n",
       "|store_and_fwd_flag|   count|\n",
       "+------------------+--------+\n",
       "|                 Y|  122061|\n",
       "|                 N|74647254|\n",
       "+------------------+--------+"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store_and_fwd_flag: if the trip was saved in the machine of the vehicle\n",
    "df.groupBy(\"store_and_fwd_flag\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>RatecodeID</th><th>count</th></tr>\n",
       "<tr><td>99</td><td>2526</td></tr>\n",
       "<tr><td>3</td><td>17687</td></tr>\n",
       "<tr><td>6</td><td>390</td></tr>\n",
       "<tr><td>1</td><td>72819739</td></tr>\n",
       "<tr><td>5</td><td>435196</td></tr>\n",
       "<tr><td>4</td><td>70956</td></tr>\n",
       "<tr><td>2</td><td>1422821</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+--------+\n",
       "|RatecodeID|   count|\n",
       "+----------+--------+\n",
       "|        99|    2526|\n",
       "|         3|   17687|\n",
       "|         6|     390|\n",
       "|         1|72819739|\n",
       "|         5|  435196|\n",
       "|         4|   70956|\n",
       "|         2| 1422821|\n",
       "+----------+--------+"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # RatecodeID\n",
    "df.groupBy(\"RatecodeID\").count()\n",
    "#99 is weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>payment_type</th><th>count</th></tr>\n",
       "<tr><td>3</td><td>98003</td></tr>\n",
       "<tr><td>1</td><td>52919826</td></tr>\n",
       "<tr><td>5</td><td>166</td></tr>\n",
       "<tr><td>4</td><td>31780</td></tr>\n",
       "<tr><td>2</td><td>21719540</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+--------+\n",
       "|payment_type|   count|\n",
       "+------------+--------+\n",
       "|           3|   98003|\n",
       "|           1|52919826|\n",
       "|           5|     166|\n",
       "|           4|   31780|\n",
       "|           2|21719540|\n",
       "+------------+--------+"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# payment_type\n",
    "df.groupBy(\"payment_type\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>taxi_type</th><th>count</th></tr>\n",
       "<tr><td>yellow</td><td>68844062</td></tr>\n",
       "<tr><td>green</td><td>5925253</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+--------+\n",
       "|taxi_type|   count|\n",
       "+---------+--------+\n",
       "|   yellow|68844062|\n",
       "|    green| 5925253|\n",
       "+---------+--------+"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taxi_type\n",
    "df.groupBy(\"taxi_type\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>trip_type</th><th>count</th></tr>\n",
       "<tr><td>null</td><td>354</td></tr>\n",
       "<tr><td>no</td><td>68844062</td></tr>\n",
       "<tr><td>1</td><td>5732115</td></tr>\n",
       "<tr><td>2</td><td>192784</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+--------+\n",
       "|trip_type|   count|\n",
       "+---------+--------+\n",
       "|     null|     354|\n",
       "|       no|68844062|\n",
       "|        1| 5732115|\n",
       "|        2|  192784|\n",
       "+---------+--------+"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trip_type\n",
    "df.groupBy(\"trip_type\").count()\n",
    "#null is weird"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will change the weird values to the most common values \n",
    "\n",
    "#vendorid 4 to class 2 (is like the driver put 2 times 2 and it is the mayority class)\n",
    "df = df.withColumn(\"VendorID\", \\\n",
    "              when(df[\"VendorID\"] == 4, 2).otherwise(df[\"VendorID\"]))\n",
    "\n",
    "# 99 to class 1 because is the mayority class, also they are only 53.\n",
    "df = df.withColumn(\"RatecodeID\", \\\n",
    "              when(df[\"RatecodeID\"] == 99, 1).otherwise(df[\"RatecodeID\"]))\n",
    "\n",
    "# null to class 1 because green are the only one that have trip_type so null is different from no\n",
    "df = df.withColumn(\"trip_type\", \\\n",
    "              when(df[\"trip_type\"].isNull(), 1).otherwise(df[\"trip_type\"]))\n",
    "\n",
    "#all another payment type does not have tip amount\n",
    "df = df.withColumn(\"tip_amount\", \\\n",
    "              when(df[\"payment_type\"] != 1 , 0).otherwise(df[\"tip_amount\"]))\n",
    "\n",
    "#not used:\n",
    "#drop all the rows that have null in the first variables above (rows that have many missing values)\n",
    "# df.na.drop(thresh=5, subset=(\"VendorID\",\"store_and_fwd_flag\", \"RatecodeID\", \"payment_type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "# how many tip amount are different from 0 and payment with other type than credit card (drop these) \n",
    "\n",
    "df.where((F.col(\"tip_amount\")!= 0) & (F.col(\"payment_type\")== 2)).count() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date data: looking outliers\n",
    "- date time coherent (min-max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>min(pickup_datetime)</th><th>max(pickup_datetime)</th><th>min(dropoff_datetime)</th><th>max(dropoff_datetime)</th></tr>\n",
       "<tr><td>2001-01-01 00:02:08</td><td>2090-12-31 06:41:26</td><td>2001-01-01 01:00:02</td><td>2090-12-31 07:18:49</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+--------------------+---------------------+---------------------+\n",
       "|min(pickup_datetime)|max(pickup_datetime)|min(dropoff_datetime)|max(dropoff_datetime)|\n",
       "+--------------------+--------------------+---------------------+---------------------+\n",
       "| 2001-01-01 00:02:08| 2090-12-31 06:41:26|  2001-01-01 01:00:02|  2090-12-31 07:18:49|\n",
       "+--------------------+--------------------+---------------------+---------------------+"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#knowing if date time is coherent\n",
    "df.select(min(\"pickup_datetime\"),max(\"pickup_datetime\"),min(\"dropoff_datetime\"),max(\"dropoff_datetime\"))\n",
    "\n",
    "#below I will take out the weird years (data engineering part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location data\n",
    "\n",
    "- From the page we know that locationID is populated by numbers ranging from 1-265.\n",
    "- Cleaning in data engineering part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick Up location id (same as DO)\n",
    "#df.groupBy(\"PULocationID\").count().show(265)\n",
    "#df.select(\"PULocationID\").distinct().show()\n",
    "\n",
    "\n",
    "# # Dropp Off location id\n",
    "# df.groupBy(\"DOLocationID\").count().show()\n",
    "# #populated by numbers ranging from 1-265."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxi zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the location of each PU and DO to get more variables to the model\n",
    "taxi_zone = spark.read.option(\"header\",True)\\\n",
    "    .csv(\"taxi_zone_lookup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>LocationID</th><th>Borough</th><th>Zone</th><th>service_zone</th></tr>\n",
       "<tr><td>1</td><td>EWR</td><td>Newark Airport</td><td>EWR</td></tr>\n",
       "<tr><td>2</td><td>Queens</td><td>Jamaica Bay</td><td>Boro Zone</td></tr>\n",
       "<tr><td>3</td><td>Bronx</td><td>Allerton/Pelham G...</td><td>Boro Zone</td></tr>\n",
       "<tr><td>4</td><td>Manhattan</td><td>Alphabet City</td><td>Yellow Zone</td></tr>\n",
       "<tr><td>5</td><td>Staten Island</td><td>Arden Heights</td><td>Boro Zone</td></tr>\n",
       "<tr><td>6</td><td>Staten Island</td><td>Arrochar/Fort Wad...</td><td>Boro Zone</td></tr>\n",
       "<tr><td>7</td><td>Queens</td><td>Astoria</td><td>Boro Zone</td></tr>\n",
       "<tr><td>8</td><td>Queens</td><td>Astoria Park</td><td>Boro Zone</td></tr>\n",
       "<tr><td>9</td><td>Queens</td><td>Auburndale</td><td>Boro Zone</td></tr>\n",
       "<tr><td>10</td><td>Queens</td><td>Baisley Park</td><td>Boro Zone</td></tr>\n",
       "<tr><td>11</td><td>Brooklyn</td><td>Bath Beach</td><td>Boro Zone</td></tr>\n",
       "<tr><td>12</td><td>Manhattan</td><td>Battery Park</td><td>Yellow Zone</td></tr>\n",
       "<tr><td>13</td><td>Manhattan</td><td>Battery Park City</td><td>Yellow Zone</td></tr>\n",
       "<tr><td>14</td><td>Brooklyn</td><td>Bay Ridge</td><td>Boro Zone</td></tr>\n",
       "<tr><td>15</td><td>Queens</td><td>Bay Terrace/Fort ...</td><td>Boro Zone</td></tr>\n",
       "<tr><td>16</td><td>Queens</td><td>Bayside</td><td>Boro Zone</td></tr>\n",
       "<tr><td>17</td><td>Brooklyn</td><td>Bedford</td><td>Boro Zone</td></tr>\n",
       "<tr><td>18</td><td>Bronx</td><td>Bedford Park</td><td>Boro Zone</td></tr>\n",
       "<tr><td>19</td><td>Queens</td><td>Bellerose</td><td>Boro Zone</td></tr>\n",
       "<tr><td>20</td><td>Bronx</td><td>Belmont</td><td>Boro Zone</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+----------+-------------+--------------------+------------+\n",
       "|LocationID|      Borough|                Zone|service_zone|\n",
       "+----------+-------------+--------------------+------------+\n",
       "|         1|          EWR|      Newark Airport|         EWR|\n",
       "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
       "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
       "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
       "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
       "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
       "|         7|       Queens|             Astoria|   Boro Zone|\n",
       "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
       "|         9|       Queens|          Auburndale|   Boro Zone|\n",
       "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
       "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
       "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
       "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
       "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
       "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
       "|        16|       Queens|             Bayside|   Boro Zone|\n",
       "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
       "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
       "|        19|       Queens|           Bellerose|   Boro Zone|\n",
       "|        20|        Bronx|             Belmont|   Boro Zone|\n",
       "+----------+-------------+--------------------+------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_zone\n",
    "#taxi_zone.count() \n",
    "#after opened the table in excel I could realise that there are 265 ID, but, the last 2 are unknown boroughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zone = taxi_zone.drop(\"service_zone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joint with the actual data using the variables above\n",
    "df = df.join(taxi_zone, df.PULocationID == taxi_zone.LocationID,how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename to avoid confusing\n",
    "df = df.drop(df.LocationID)\\\n",
    "       .withColumnRenamed(\"Borough\", \"Borough_PU\")\\\n",
    "       .withColumnRenamed('Zone', 'Zone_PU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(taxi_zone, df.DOLocationID == taxi_zone.LocationID,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.LocationID)\\\n",
    "       .withColumnRenamed(\"Borough\", \"Borough_DO\")\\\n",
    "       .withColumnRenamed('Zone', 'Zone_DO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Borough_DO</th><th>avg(total_amount)</th></tr>\n",
       "<tr><td>EWR</td><td>91.90575069663404</td></tr>\n",
       "<tr><td>Brooklyn</td><td>27.615433490806645</td></tr>\n",
       "<tr><td>Manhattan</td><td>16.510041452563392</td></tr>\n",
       "<tr><td>Bronx</td><td>27.60353242664853</td></tr>\n",
       "<tr><td>Queens</td><td>27.968154936483785</td></tr>\n",
       "<tr><td>Unknown</td><td>30.48763576879663</td></tr>\n",
       "<tr><td>Staten Island</td><td>36.1084090558494</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------+------------------+\n",
       "|   Borough_DO| avg(total_amount)|\n",
       "+-------------+------------------+\n",
       "|          EWR| 91.90575069663404|\n",
       "|     Brooklyn|27.615433490806645|\n",
       "|    Manhattan|16.510041452563392|\n",
       "|        Bronx| 27.60353242664853|\n",
       "|       Queens|27.968154936483785|\n",
       "|      Unknown| 30.48763576879663|\n",
       "|Staten Island|  36.1084090558494|\n",
       "+-------------+------------------+"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unique values in borough and knowing the average total amount: Exploration about more expensive trips\n",
    "df.groupBy(\"Borough_DO\").agg(\n",
    "      F.avg(\"total_amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Borough_PU</th><th>avg(total_amount)</th></tr>\n",
       "<tr><td>EWR</td><td>89.73858680725098</td></tr>\n",
       "<tr><td>Brooklyn</td><td>18.150877444848415</td></tr>\n",
       "<tr><td>Manhattan</td><td>16.435924363871955</td></tr>\n",
       "<tr><td>Bronx</td><td>20.880524697076947</td></tr>\n",
       "<tr><td>Queens</td><td>35.5660721397699</td></tr>\n",
       "<tr><td>Unknown</td><td>18.989862115304422</td></tr>\n",
       "<tr><td>Staten Island</td><td>51.43676536436079</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------+------------------+\n",
       "|   Borough_PU| avg(total_amount)|\n",
       "+-------------+------------------+\n",
       "|          EWR| 89.73858680725098|\n",
       "|     Brooklyn|18.150877444848415|\n",
       "|    Manhattan|16.435924363871955|\n",
       "|        Bronx|20.880524697076947|\n",
       "|       Queens|  35.5660721397699|\n",
       "|      Unknown|18.989862115304422|\n",
       "|Staten Island| 51.43676536436079|\n",
       "+-------------+------------------+"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"Borough_PU\").agg(\n",
    "      F.avg(\"total_amount\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above different Borough have different total amount, been EWR the most expensive (airport)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter areas with unkown borough\n",
    "df = df.where((F.col(\"Borough_PU\")!= \"Unknown\") & (F.col(\"Borough_DO\")!= \"Unknown\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New variables for datetime\n",
    "- for datetime variables: year, quarter, months, dayweek, hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating year,month,dayweek,etc\n",
    "df = df.withColumn(\"year\", date_format(col(\"dropoff_datetime\"), \"Y\"))\\\n",
    "       .withColumn(\"month\", date_format(col(\"dropoff_datetime\"), \"M\"))\\\n",
    "       .withColumn('dow',dayofweek(df.dropoff_datetime))\\\n",
    "       .withColumn('quarter',quarter(df.dropoff_datetime))\\\n",
    "       .withColumn(\"dow_long\", date_format(col(\"dropoff_datetime\"), \"EEEE\")) \\\n",
    "       .withColumn('hour',hour(df.dropoff_datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|year|   count|\n",
      "+----+--------+\n",
      "|2091|       1|\n",
      "|2002|      11|\n",
      "|2033|       3|\n",
      "|2020|17288473|\n",
      "|2026|       1|\n",
      "|2018|       1|\n",
      "|2010|      39|\n",
      "|2029|       3|\n",
      "|2003|       3|\n",
      "|2009|     678|\n",
      "|2066|       1|\n",
      "|2021|  134487|\n",
      "|2058|       3|\n",
      "|2008|       2|\n",
      "|2001|       2|\n",
      "|2019|56507535|\n",
      "|2038|       4|\n",
      "+----+--------+\n",
      "\n",
      "+-----+-------+\n",
      "|month|  count|\n",
      "+-----+-------+\n",
      "|    7|4978612|\n",
      "|    9|5502743|\n",
      "|    3|7681426|\n",
      "|    6|5237043|\n",
      "|    1|7291052|\n",
      "|   11|5854317|\n",
      "|    8|4946055|\n",
      "|    5|5500005|\n",
      "|   10|6170191|\n",
      "|    4|5332838|\n",
      "|   12|5870572|\n",
      "|    2|9566393|\n",
      "+-----+-------+\n",
      "\n",
      "+---+--------+\n",
      "|dow|   count|\n",
      "+---+--------+\n",
      "|  1| 9131605|\n",
      "|  6|11357614|\n",
      "|  3|10692660|\n",
      "|  4|11082395|\n",
      "|  5|11398215|\n",
      "|  2| 9627573|\n",
      "|  7|10641185|\n",
      "+---+--------+\n",
      "\n",
      "+----+-------+\n",
      "|hour|  count|\n",
      "+----+-------+\n",
      "|  12|3918773|\n",
      "|   1|1599764|\n",
      "|   6|1254475|\n",
      "|   3| 732385|\n",
      "|   4| 566424|\n",
      "|   8|3256782|\n",
      "|  11|3667879|\n",
      "|  19|4765365|\n",
      "|  23|3178994|\n",
      "|  21|4056554|\n",
      "|  14|4072163|\n",
      "|  16|4022503|\n",
      "|  20|4159124|\n",
      "|   5| 562246|\n",
      "|  15|4215419|\n",
      "|   2|1070846|\n",
      "|  18|4939629|\n",
      "|  13|3913519|\n",
      "|  17|4292128|\n",
      "|   7|2347989|\n",
      "|   0|2357977|\n",
      "|  22|3842872|\n",
      "|   9|3559840|\n",
      "|  10|3577597|\n",
      "+----+-------+\n",
      "\n",
      "+-------+--------+\n",
      "|quarter|   count|\n",
      "+-------+--------+\n",
      "|      1|24538871|\n",
      "|      3|15427410|\n",
      "|      4|17895080|\n",
      "|      2|16069886|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# value counts for these new variables\n",
    "df.groupBy(\"year\").count().show()\n",
    "df.groupBy(\"month\").count().show(13)\n",
    "df.groupBy(\"dow\").count().show(8)\n",
    "df.groupBy(\"hour\").count().show(26)\n",
    "df.groupBy(\"quarter\").count().show(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as mention above, years out of 2019-2020 were take out\n",
    "df = df.where((F.col(\"year\")>2018) & (F.col(\"year\")<2021))\n",
    "#df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new variable bin for each time of a day\n",
    "def categorizerdate(x):\n",
    "    if (x >= 0) & (x<5):\n",
    "        return \"early morning\"\n",
    "    elif (x >= 5) & (x <12):\n",
    "        return \"morning\"\n",
    "    elif (x >= 12) & (x <16):\n",
    "        return \"afternoon\"\n",
    "    elif (x >= 16) & (x <20):\n",
    "        return \"evening\"\n",
    "    elif (x >= 20) & (x <=23):\n",
    "        return \"late night\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_udf = udf(categorizerdate, StringType() )\n",
    "df = df.withColumn(\"day_time\", bucket_udf(\"hour\")) #time of a day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New variable Duration\n",
    "- difference between pickup and dropoff time in minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here I put the duration in minutes (I divide the difference by 60) \n",
    "\n",
    "df = df.withColumn(\"duration\", \n",
    "    (F.col(\"dropoff_datetime\").cast(\"long\") - F.col(\"pickup_datetime\").cast(\"long\"))/60.)\n",
    "\n",
    "#first outliers\n",
    "df = df.where(F.col(\"duration\")>=0) #drop datetime dropoff before pickup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|         duration|\n",
      "+-------+-----------------+\n",
      "|  count|         73795576|\n",
      "|   mean|19.02444278344467|\n",
      "| stddev|83.81551403619875|\n",
      "|    min|              0.0|\n",
      "|    max|43648.01666666667|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(\"duration\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning: \n",
    "- 3 st deviation from the mean as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trip duration: more than 0 but less than a a 3 st of the mean: 270 == 4.5 hours .. it is a lot but we do not have more information\n",
    "df = df.where( (F.col(\"duration\")< 270)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logical cases as above: fare, distance, duration\n",
    "\n",
    "df = df.where((F.col(\"fare_amount\")> 2.50) & (F.col(\"trip_distance\")!=0) & (F.col(\"duration\")!=0) | (F.col(\"total_amount\")<= 6.55) & (F.col(\"trip_distance\")==0) & (F.col(\"duration\")==0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bins for duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizer(duration):\n",
    "    if duration < 5:\n",
    "        return \"short1\"\n",
    "    elif (duration >= 5) & (duration <10):\n",
    "        return \"short2\"\n",
    "    elif (duration >= 10) & (duration <20):\n",
    "        return \"middle\"\n",
    "    elif (duration >= 20) & (duration <30):\n",
    "        return \"long1\"\n",
    "    elif (duration >= 30):\n",
    "        return \"long2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_udf = udf(categorizer, StringType() )\n",
    "df = df.withColumn(\"bins_duration\", bucket_udf(\"duration\")) #duration in minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New variable: Average paid per passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new variable (not used in the model)\n",
    "df= df.withColumn(\"av_paid\", df.total_amount/df.passenger_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>av_paid</th></tr>\n",
       "<tr><td>count</td><td>73319398</td></tr>\n",
       "<tr><td>mean</td><td>14.835076567775145</td></tr>\n",
       "<tr><td>stddev</td><td>12.221611337018498</td></tr>\n",
       "<tr><td>min</td><td>0.5</td></tr>\n",
       "<tr><td>max</td><td>393.6400146484375</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+------------------+\n",
       "|summary|           av_paid|\n",
       "+-------+------------------+\n",
       "|  count|          73319398|\n",
       "|   mean|14.835076567775145|\n",
       "| stddev|12.221611337018498|\n",
       "|    min|               0.5|\n",
       "|    max| 393.6400146484375|\n",
       "+-------+------------------+"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(\"av_paid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New variable Speed(km/hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"speed\", (df.trip_distance*1.6)/((df.duration)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>speed</th></tr>\n",
       "<tr><td>count</td><td>73319250</td></tr>\n",
       "<tr><td>mean</td><td>19.434548894936395</td></tr>\n",
       "<tr><td>stddev</td><td>117.86501467078517</td></tr>\n",
       "<tr><td>min</td><td>0.003690415089219...</td></tr>\n",
       "<tr><td>max</td><td>150566.396484375</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+--------------------+\n",
       "|summary|               speed|\n",
       "+-------+--------------------+\n",
       "|  count|            73319250|\n",
       "|   mean|  19.434548894936395|\n",
       "| stddev|  117.86501467078517|\n",
       "|    min|0.003690415089219...|\n",
       "|    max|    150566.396484375|\n",
       "+-------+--------------------+"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(\"speed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I assume the min speed is 0 and the max speed is 220\n",
    "df = df.where((F.col(\"speed\")<=220) & (F.col(\"speed\")>=0))\n",
    "\n",
    "# the max speed is 220 asumming a taxi could not go too fast, but probably the maximun should be less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New variable bins of distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizerdist(distance):\n",
    "    if distance < 5:\n",
    "        return \"short1\"\n",
    "    elif (distance >= 5) & (distance <20):\n",
    "        return \"short2\"\n",
    "    elif (distance >= 20) & (distance <40):\n",
    "        return \"middle\"\n",
    "    elif (distance >= 40) & (distance <60):\n",
    "        return \"long1\"\n",
    "    elif (distance >= 60):\n",
    "        return \"long2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_udf = udf(categorizerdist, StringType() )\n",
    "df = df.withColumn(\"bins_distance\", bucket_udf(\"trip_distance\")) #duration in minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cheking missing values again to export the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>pickup_datetime</th><th>dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>taxi_type</th><th>ehail_fee</th><th>trip_type</th><th>Borough_PU</th><th>Zone_PU</th><th>Borough_DO</th><th>Zone_DO</th><th>year</th><th>month</th><th>dow</th><th>quarter</th><th>dow_long</th><th>hour</th><th>day_time</th><th>duration</th><th>bins_duration</th><th>av_paid</th><th>speed</th><th>bins_distance</th></tr>\n",
       "<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>5821305</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+---------+----------+-------+----------+-------+----+-----+---+-------+--------+----+--------+--------+-------------+-------+-----+-------------+\n",
       "|VendorID|pickup_datetime|dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|taxi_type|ehail_fee|trip_type|Borough_PU|Zone_PU|Borough_DO|Zone_DO|year|month|dow|quarter|dow_long|hour|day_time|duration|bins_duration|av_paid|speed|bins_distance|\n",
       "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+---------+----------+-------+----------+-------+----+-----+---+-------+--------+----+--------+--------+-------------+-------+-----+-------------+\n",
       "|       0|              0|               0|              0|            0|         0|                 0|           0|           0|           0|          0|    0|      0|         0|           0|                    0|           0|                   0|        0|  5821305|        0|         0|      0|         0|      0|   0|    0|  0|      0|       0|   0|       0|       0|            0|      0|    0|            0|\n",
       "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+---------+----------+-------+----------+-------+----+-----+---+-------+--------+----+--------+--------+-------------+-------+-----+-------------+"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns))\n",
    "#only ehaill fee has missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows columns\n",
      "(73297413, 37)\n"
     ]
    }
   ],
   "source": [
    "#number the rows and columns\n",
    "count = df.count()\n",
    "print(\"rows\",\"columns\")\n",
    "print((count, len(df.columns)))\n",
    "\n",
    "#its aprox 63% of the original data, but because it is big data, its still a lot of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames can be saved as Parquet files, maintaining the schema information.\n",
    "#df.write.parquet(\"df_clean.parquet\")\n",
    "\n",
    "df.write.mode('overwrite').parquet(\"df_clean.parquet\")\n",
    "\n",
    "#I used it because it has a fast reading. That was useful to make the queries below in different days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Answer the list of provided business questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "parqDF=spark.read.parquet(\"df_clean.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create temporary view for to run faster queries\n",
    "\n",
    "#parquet df\n",
    "parqDF.createOrReplaceTempView(\"df_par\")\n",
    "\n",
    "#spark df\n",
    "#df.createOrReplaceTempView(\"df_par\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. For each year and month:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the total number of trips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparksql\n",
    "#df.groupBy(\"year\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------+\n",
      "|year|month|n_trips|\n",
      "+----+-----+-------+\n",
      "|2020|    4| 152445|\n",
      "|2020|    5| 198245|\n",
      "|2020|    6| 338796|\n",
      "|2020|    7| 501566|\n",
      "|2020|    8| 662063|\n",
      "|2020|    9| 886474|\n",
      "|2020|   11|1001497|\n",
      "|2020|   10|1117900|\n",
      "|2020|   12|1206911|\n",
      "|2020|    3|2141049|\n",
      "|2019|    1|2733703|\n",
      "|2019|    8|4247183|\n",
      "|2019|    7|4440139|\n",
      "|2020|    2|4455335|\n",
      "|2019|   12|4491394|\n",
      "|2020|    1|4514960|\n",
      "|2019|    9|4577649|\n",
      "|2019|   11|4812995|\n",
      "|2019|    6|4861047|\n",
      "|2019|   10|5010768|\n",
      "|2019|    2|5048379|\n",
      "|2019|    4|5143664|\n",
      "|2019|    5|5263851|\n",
      "|2019|    3|5489400|\n",
      "+----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT \n",
    " year, month\n",
    " , COUNT(1) n_trips\n",
    "FROM df_par\n",
    "GROUP BY year, month\n",
    "ORDER BY n_trips\n",
    "''').show(24)\n",
    "\n",
    "#almost all the months in 2020 have few trips than 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which hour of the day had the most trips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark sql\n",
    "#df.groupBy(\"year\",\"hour\").count().sort(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+------+\n",
      "|year|month|hour| trips|\n",
      "+----+-----+----+------+\n",
      "|2020|    4|  15| 11334|\n",
      "|2020|    5|  15| 15165|\n",
      "|2020|    6|  15| 25205|\n",
      "|2020|    7|  15| 36458|\n",
      "|2020|    8|  15| 47840|\n",
      "|2020|    9|  18| 66575|\n",
      "|2020|   11|  15| 80113|\n",
      "|2020|   10|  18| 83117|\n",
      "|2020|   12|  15| 94203|\n",
      "|2020|    3|  18|148983|\n",
      "|2019|    1|  18|186963|\n",
      "|2019|    8|  18|279397|\n",
      "|2019|   12|  19|285928|\n",
      "|2019|    7|  18|289743|\n",
      "|2019|    9|  18|302445|\n",
      "|2020|    2|  18|309373|\n",
      "|2019|    6|  18|310187|\n",
      "|2020|    1|  18|310445|\n",
      "|2019|   11|  18|317974|\n",
      "|2019|   10|  19|333422|\n",
      "|2019|    2|  18|335561|\n",
      "|2019|    4|  18|344770|\n",
      "|2019|    5|  18|352855|\n",
      "|2019|    3|  18|363012|\n",
      "+----+-----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "WITH x AS\n",
    "(\n",
    "    SELECT year, month, hour, COUNT(*) AS trips\n",
    "    FROM df_par\n",
    "    GROUP BY year,month, hour\n",
    ")\n",
    "SELECT x.year, x.month, x.hour, x.trips\n",
    "FROM x\n",
    "INNER JOIN\n",
    "(\n",
    "    SELECT year,month, MAX( trips ) AS maxCountX\n",
    "    FROM x\n",
    "    GROUP BY year,month\n",
    ") x2\n",
    "ON x2.maxCountX = x.trips\n",
    "Order by trips\n",
    "''').show(24)\n",
    "# most trips at 18 (15 of 24) and others at 15 pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which weekday had the most trips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark SQL\n",
    "# w = Window().partitionBy(\"month\").orderBy(F.desc(\"count\"))\n",
    "\n",
    "# df_with_rank = (df_agg\n",
    "#     .withColumn(\"rank\", F.dense_rank().over(w)))\n",
    "\n",
    "# df_with_rank.where(F.col(\"rank\") == 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---------+------+\n",
      "|year|month| dow_long| trips|\n",
      "+----+-----+---------+------+\n",
      "|2019|    3|   Friday|955978|\n",
      "|2019|    2|   Friday|863399|\n",
      "|2019|   12|   Friday|696089|\n",
      "|2019|    6| Saturday|815457|\n",
      "|2019|   11| Saturday|844033|\n",
      "|2019|    9|   Sunday|684498|\n",
      "|2019|   10| Thursday|862885|\n",
      "|2019|    5| Thursday|909829|\n",
      "|2019|    8| Thursday|754486|\n",
      "|2019|    1| Thursday|549746|\n",
      "|2019|    4|  Tuesday|863916|\n",
      "|2019|    7|Wednesday|776055|\n",
      "|2020|    5|   Friday| 38132|\n",
      "|2020|    1|   Friday|784626|\n",
      "|2020|    8|   Monday|109579|\n",
      "|2020|   11|   Monday|169296|\n",
      "|2020|    2| Saturday|777383|\n",
      "|2020|    4| Thursday| 28077|\n",
      "|2020|    7| Thursday| 93379|\n",
      "|2020|   10| Thursday|204167|\n",
      "|2020|    3|  Tuesday|332539|\n",
      "|2020|   12|  Tuesday|275965|\n",
      "|2020|    6|  Tuesday| 62357|\n",
      "|2020|    9|Wednesday|164195|\n",
      "+----+-----+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "WITH x AS\n",
    "(\n",
    "    SELECT year, month, dow_long, COUNT(*) AS trips\n",
    "    FROM df_par\n",
    "    GROUP BY year,month, dow_long\n",
    ")\n",
    "SELECT x.year,x.month, x.dow_long, x.trips\n",
    "FROM x\n",
    "INNER JOIN\n",
    "(\n",
    "    SELECT year,month, MAX( trips ) AS maxCountX\n",
    "    FROM x\n",
    "    GROUP BY year,month\n",
    ") x2\n",
    "ON x2.maxCountX = x.trips\n",
    "Order by year, dow_long\n",
    "''').show(24)\n",
    "#the most repeated weekday in the two years was thursday, and people travel less in taxis on sunday, monday and wednesday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the average number of passengers? \n",
    "\n",
    "- assumption: maximun of 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SparkSQL\n",
    "#df.groupBy(\"year\").avg( \"passenger_count\")\n",
    "#df.describe(\"passenger_count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------------------+\n",
      "|year|month|          avg_pass|\n",
      "+----+-----+------------------+\n",
      "|2019|    1|1.5753796224388676|\n",
      "|2019|   10|1.6673266453366031|\n",
      "|2019|   11|1.6634735751855134|\n",
      "|2019|   12|1.6526546101277242|\n",
      "|2019|    2|1.7157715377549903|\n",
      "|2019|    3|1.7255292017342514|\n",
      "|2019|    4|1.7193510307049604|\n",
      "|2019|    5| 1.713222885678185|\n",
      "|2019|    6|1.7002939901630245|\n",
      "|2019|    7| 1.699389816399892|\n",
      "|2019|    8|1.6989548131078882|\n",
      "|2019|    9|1.6834604400643212|\n",
      "|2020|    1| 1.632525648067757|\n",
      "|2020|   10| 1.548797745773325|\n",
      "|2020|   11|1.5367884277236976|\n",
      "|2020|   12|1.5803145385202388|\n",
      "|2020|    2|1.6228101815015032|\n",
      "|2020|    3|1.5905446348962589|\n",
      "|2020|    4| 1.427072058775296|\n",
      "|2020|    5|1.4593558475623598|\n",
      "|2020|    6|1.5027420630704023|\n",
      "|2020|    7|1.5231475020236618|\n",
      "|2020|    8|1.5356151906993745|\n",
      "|2020|    9|1.5423159618894633|\n",
      "+----+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#year\n",
    "spark.sql('''\n",
    "SELECT \n",
    " year, month\n",
    " , AVG(passenger_count) avg_pass\n",
    "FROM df_par\n",
    "GROUP BY year, month\n",
    "Order by year,month\n",
    "''').show(24)\n",
    "#almost all the months in the two years have on average of 2 passengers per trip\n",
    "#Only april 2020 have 1 passenger after rounded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the average amount paid per trip (total_amount)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparkSQL\n",
    "# df.groupBy(\"year\").avg( \"total_amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------------------+\n",
      "|year|month|    avg_tot_amount|\n",
      "+----+-----+------------------+\n",
      "|2019|    1|15.096294748356863|\n",
      "|2019|   10|18.869977676019314|\n",
      "|2019|   11|18.571725949140497|\n",
      "|2019|   12|18.721124848093712|\n",
      "|2019|    2|18.036768584663175|\n",
      "|2019|    3|18.567307344125382|\n",
      "|2019|    4|18.530467365477495|\n",
      "|2019|    5| 18.85895335140635|\n",
      "|2019|    6|18.972481721704433|\n",
      "|2019|    7| 18.71558866978898|\n",
      "|2019|    8|18.709218650467744|\n",
      "|2019|    9|19.007221638322868|\n",
      "|2020|    1|17.850002345749367|\n",
      "|2020|   10|16.432112214216787|\n",
      "|2020|   11|16.334123382101073|\n",
      "|2020|   12|16.782228968766717|\n",
      "|2020|    2| 17.87319769034908|\n",
      "|2020|    3| 17.63022656460476|\n",
      "|2020|    4|15.327375863020611|\n",
      "|2020|    5|15.754282578319412|\n",
      "|2020|    6|16.730792409476525|\n",
      "|2020|    7| 16.64126167410382|\n",
      "|2020|    8|16.667475996871243|\n",
      "|2020|    9| 16.50839015831163|\n",
      "+----+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT \n",
    " year, month\n",
    " , AVG(total_amount) avg_tot_amount\n",
    "FROM df_par\n",
    "GROUP BY year, month\n",
    "ORDER BY year,month\n",
    "''').show(24)\n",
    "#It could be seeen that on average trips in 2020 were cheaper than 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the average amount paid per passenger (total_amount)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#year\n",
    "# df.groupBy(\"year\").avg( \"av_paid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------------------+\n",
      "|year|month|           avg_ppp|\n",
      "+----+-----+------------------+\n",
      "|2019|    1|12.581860001105474|\n",
      "|2019|   10| 15.31556331966309|\n",
      "|2019|   11|15.083163967273954|\n",
      "|2019|   12|15.207953932412295|\n",
      "|2019|    2|14.558124805878265|\n",
      "|2019|    3|14.947923602348268|\n",
      "|2019|    4|14.884629502462765|\n",
      "|2019|    5|  15.1721931423285|\n",
      "|2019|    6|15.292627259584567|\n",
      "|2019|    7| 15.05255132379084|\n",
      "|2019|    8|15.038600577625951|\n",
      "|2019|    9|15.364268120960881|\n",
      "|2020|    1|14.639396892337118|\n",
      "|2020|   10|13.800163751637143|\n",
      "|2020|   11| 13.76754429925853|\n",
      "|2020|   12|13.922603903424715|\n",
      "|2020|    2|14.705244765235154|\n",
      "|2020|    3| 14.65821195844199|\n",
      "|2020|    4|13.503782270454625|\n",
      "|2020|    5|13.695092579936892|\n",
      "|2020|    6| 14.32963459427532|\n",
      "|2020|    7|14.131913231334824|\n",
      "|2020|    8|14.062551362994341|\n",
      "|2020|    9|13.897527495012008|\n",
      "+----+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT \n",
    " year,month\n",
    " , AVG(total_amount/passenger_count) avg_ppp\n",
    "FROM df_par\n",
    "GROUP BY year, month\n",
    "ORDER BY year, month\n",
    "''').show(24)\n",
    "#as the same as before, the paid per passenger was less in 2020 than in 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.  For each taxi colour (yellow and green)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the average, median, minimum and maximum trip duration in seconds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupBy(\"taxi_type\").agg(\n",
    "#       F.min(\"duration\")*60,\n",
    "#       F.avg(\"duration\")*60,\n",
    "#       F.max(\"duration\")*60).show()\n",
    "#       #F.approxQuantile(\"duration\", [0.5], 0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+-------+------------------+----------+\n",
      "|taxi_type|          avg_dur|min_dur|           max_dur|median_dur|\n",
      "+---------+-----------------+-------+------------------+----------+\n",
      "|   yellow|843.0866080577625|    1.0|           16197.0|     679.0|\n",
      "|    green| 854.211110441199|    1.0|16191.000000000002|     679.0|\n",
      "+---------+-----------------+-------+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT \n",
    " taxi_type\n",
    " , AVG(duration*60)  avg_dur \n",
    " , MIN(duration*60)  min_dur\n",
    " , MAX(duration*60)  max_dur\n",
    " , approx_percentile(duration*60, 0.5, 100) median_dur\n",
    "FROM df_par\n",
    "GROUP BY taxi_type\n",
    "''').show()\n",
    "#Since the minimun assumed in the cleaning part was 0, it could be see that the min in sec is 1.\n",
    "#Also, the maximun is less than 270 (assumption before)\n",
    "#The average of yellow if less than green but booth near 850 (14 minutes). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, it interesting to see that the average is higher than the median. Therefore, it is probably that the trips with duration near the maximum are few."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the average, median, minimum and maximum trip distance in km?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark sql\n",
    "# df.groupBy(\"taxi_type\").agg(\n",
    "#       F.min(\"trip_dist_km\"),\n",
    "#       F.avg(\"trip_dist_km\"),\n",
    "#       F.max(\"trip_dist_km\")).show()\n",
    "#       #F.approxQuantile(\"duration\", [0.5], 0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+--------------------+------------------+------------------+\n",
      "|taxi_type|           avg_td|              min_td|            max_td|         median_td|\n",
      "+---------+-----------------+--------------------+------------------+------------------+\n",
      "|   yellow|4.735446221545285|0.015999999642372132|158.99200439453125|2.7200000762939456|\n",
      "|    green| 4.76187468326689|0.015999999642372132| 135.5199951171875| 2.992000007629395|\n",
      "+---------+-----------------+--------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT \n",
    " taxi_type\n",
    " , AVG(trip_distance*1.6)  avg_td \n",
    " , MIN(trip_distance*1.6)  min_td\n",
    " , MAX(trip_distance*1.6)  max_td\n",
    " ,approx_percentile(trip_distance*1.6, 0.5, 100) median_td\n",
    "FROM df_par\n",
    "GROUP BY taxi_type''').show()\n",
    "#the minimum is 0 because the assumptions in the cleaning part. The same for the maximun.\n",
    "#As above, the average is like two times of the median probably because some trips are near the maximun but they are few.\n",
    "#It is very similar between taxy type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the average, median, minimum and maximum speed in km per hour? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+--------------------+------------------+------------------+\n",
      "|taxi_type|     avg_speed_km|        min_speed_km|      max_speed_km|   median_speed_km|\n",
      "+---------+-----------------+--------------------+------------------+------------------+\n",
      "|   yellow| 18.6772211546339|0.003690415089219...|219.92726586081767|  16.3265306122449|\n",
      "|    green|19.11572623111619|0.006349906152854...|219.92726586081767|17.209756432510005|\n",
      "+---------+-----------------+--------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT \n",
    " taxi_type\n",
    " , AVG((trip_distance*1.6)/(duration/60))  avg_speed_km \n",
    " , MIN((trip_distance*1.6)/(duration/60))  min_speed_km\n",
    " , MAX((trip_distance*1.6)/(duration/60))  max_speed_km\n",
    " , approx_percentile((trip_distance*1.6)/(duration/60), 0.5, 100) median_speed_km\n",
    "FROM df_par\n",
    "GROUP BY taxi_type''').show()\n",
    "#green and yellow have almost the same average speed.\n",
    "#The maximun and minumum are inside the range assumed above\n",
    "#the average and median its not very different, probably there are few outliers here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. What was the percentage of trips where the driver received tips?\n",
    "\n",
    "- assumption, only for payment_type = credit card because for cash NYC dataset does not have the information\n",
    "- also, for another payment type it was assumed that there is not a tip because they are related with no payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.where(df.tip_amount>0).count()/df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|    perc_with_tips|\n",
      "+------------------+\n",
      "|0.9462256074176378|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "select \n",
    "(select count(*) from df_par where payment_type =1 AND tip_amount>0)/ count(*) as perc_with_tips\n",
    "from df_par \n",
    "where payment_type =1\n",
    "''').show()\n",
    "#only considering credit card, 95% of the time the taxis received tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corraborate its ok\n",
    "\n",
    "# spark.sql('''\n",
    "# select count(*)\n",
    "# from df_par\n",
    "# where payment_type =1 AND tip_amount>0\n",
    "# ''').show()\n",
    "\n",
    "# spark.sql('''\n",
    "# select count(*)\n",
    "# from df_par\n",
    "# where payment_type =1 \n",
    "# ''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. For trips where the driver received tips, What was the percentage where the driver received tips of at least $10.\n",
    "\n",
    "- the same assumption as below, only for payment_type = credit card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.where(df.tip_amount>10).count()/df.where(df.tip_amount>0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|      perc_with_tips|\n",
      "+--------------------+\n",
      "|0.030831322526626518|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "select \n",
    "(select count(*) from df_par where payment_type =1 AND tip_amount >= 10)/ count(*) as perc_with_tips\n",
    "from df_par \n",
    "where payment_type =1 and tip_amount > 0\n",
    "''').show()\n",
    "#only 3% of the time the driver recieves a tip of at least 10 using credit card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Classify each trip into bins of durations:\n",
    "- Under 5 Mins,From 5 mins to 10 mins,From 10 mins to 20 mins,From 20 mins to 30 mins,At least 30 mins\n",
    "- Then for each bins, calculate: Average speed (km per hour) and Average distance per dollar (km per $)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+-------------------+\n",
      "|duration_bins|         ave_speed|    ave_dist_dollar|\n",
      "+-------------+------------------+-------------------+\n",
      "|          >30|25.703337447297155|0.35497007534492064|\n",
      "|           <5| 19.62316593317579|0.12833775722739388|\n",
      "|        10-20|17.436047735429053| 0.2285887630802899|\n",
      "|        20-30|21.347825394595272| 0.2856627274076294|\n",
      "|         5-10|16.803196441768144|0.17656291442405736|\n",
      "+-------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT \n",
    "  CASE  WHEN duration < 5 THEN \"<5\"\n",
    "      WHEN duration >=5 AND duration <10 THEN \"5-10\"\n",
    "      WHEN duration >=10 AND duration <20 THEN \"10-20\"\n",
    "      WHEN duration >=20 AND duration <30 THEN \"20-30\"\n",
    "      WHEN duration >=30 THEN \">30\" \n",
    "      END as duration_bins,\n",
    "  AVG((trip_distance*1.6)/(duration/60)) as ave_speed,\n",
    "  AVG((trip_distance*1.6)/(total_amount)) as ave_dist_dollar\n",
    "FROM df_par\n",
    "GROUP BY \n",
    "  CASE  WHEN duration < 5 THEN \"<5\"\n",
    "      WHEN duration >=5 AND duration <10 THEN \"5-10\"\n",
    "      WHEN duration >=10 AND duration <20 THEN \"10-20\"\n",
    "      WHEN duration >=20 AND duration <30 THEN \"20-30\"\n",
    "      WHEN duration >=30 THEN \">30\" \n",
    "      END\n",
    "''').show()\n",
    "#the less average distance per dollar is in bin <5 minutes trip. \n",
    "#But it is interesting that the average speed is higher than 5-10 and 10-20 min. \n",
    "#Its like that more duration more probability of traffic congestion, so less speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Which duration bin will you advise a taxi driver to target to maximise his income?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the bin that gives less distance per dollar shloud be the target because for less distance the driver receives 1 dollar.\n",
    "#the driver should target trips of less than 5 minutes because its receives 1 dollar in 0,13 km."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Build a ML model to predict the Total fare amount of a trip - GCP PART\n",
    "- based for the last 3 months of data (train your data on the remaining dataset). \n",
    "- You are not allowed to use fare_amount as a feature for your model. \n",
    "- The model will be assessed using the RMSE score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data from google storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Cloud Storage Bucket\n",
    "gcs_bucket = 'parquet_df'\n",
    "folder = 'df_clean.parquet'\n",
    "\n",
    "parqDF=spark.read.parquet('gs://{}/{}'.format(gcs_bucket,folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "\n",
    "Selection of columns to use:\n",
    "- 1. Some variables were dropped\n",
    "- 2. Correlation of the numerical variables with the total amount \n",
    "- 3. Relation of the categorical variables and total amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parqDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>pickup_datetime</th><th>dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>taxi_type</th><th>ehail_fee</th><th>trip_type</th><th>Borough_PU</th><th>Zone_PU</th><th>Borough_DO</th><th>Zone_DO</th><th>year</th><th>month</th><th>dow</th><th>quarter</th><th>dow_long</th><th>hour</th><th>day_time</th><th>duration</th><th>bins_duration</th><th>av_paid</th><th>speed</th><th>bins_distance</th></tr>\n",
       "<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>5829694</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+---------+----------+-------+----------+-------+----+-----+---+-------+--------+----+--------+--------+-------------+-------+-----+-------------+\n",
       "|VendorID|pickup_datetime|dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|taxi_type|ehail_fee|trip_type|Borough_PU|Zone_PU|Borough_DO|Zone_DO|year|month|dow|quarter|dow_long|hour|day_time|duration|bins_duration|av_paid|speed|bins_distance|\n",
       "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+---------+----------+-------+----------+-------+----+-----+---+-------+--------+----+--------+--------+-------------+-------+-----+-------------+\n",
       "|       0|              0|               0|              0|            0|         0|                 0|           0|           0|           0|          0|    0|      0|         0|           0|                    0|           0|                   0|        0|  5829694|        0|         0|      0|         0|      0|   0|    0|  0|      0|       0|   0|       0|       0|            0|      0|    0|            0|\n",
       "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+---------+----------+-------+----------+-------+----+-----+---+-------+--------+----+--------+--------+-------------+-------+-----+-------------+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing values again (from parquet files in GCP)\n",
    "df.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'RatecodeID',\n",
       " 'store_and_fwd_flag',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'congestion_surcharge',\n",
       " 'taxi_type',\n",
       " 'ehail_fee',\n",
       " 'trip_type',\n",
       " 'Borough_PU',\n",
       " 'Zone_PU',\n",
       " 'Borough_DO',\n",
       " 'Zone_DO',\n",
       " 'year',\n",
       " 'month',\n",
       " 'dow',\n",
       " 'quarter',\n",
       " 'dow_long',\n",
       " 'hour',\n",
       " 'day_time',\n",
       " 'duration',\n",
       " 'bins_duration',\n",
       " 'av_paid',\n",
       " 'speed',\n",
       " 'bins_distance']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataframe to avoid change df\n",
    "df_model = df\n",
    "#df_model = df.sample(withReplacement=False, fraction=0.001) #to try with subsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropp some columns\n",
    "- datetime was dropped because it is one value per row\n",
    "- Location ID was dropped because it has 263 values\n",
    "- ehail_fee because it has many missing values and yellow taxis do not have it so I put 0\n",
    "- average paid because it was created with total amount\n",
    "- fare amount because it was mandatory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_model.drop(\"fare_amount\", \"ehail_fee\", \"pickup_datetime\", \"dropoff_datetime\", \"PULocationID\", \"DOLocationID\", \"Zone_PU\", \"Zone_PU\", \"av_paid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: float (nullable = true)\n",
      " |-- RatecodeID: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- extra: float (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: float (nullable = true)\n",
      " |-- tolls_amount: float (nullable = true)\n",
      " |-- improvement_surcharge: float (nullable = true)\n",
      " |-- total_amount: float (nullable = true)\n",
      " |-- congestion_surcharge: float (nullable = true)\n",
      " |-- taxi_type: string (nullable = true)\n",
      " |-- trip_type: string (nullable = true)\n",
      " |-- Borough_PU: string (nullable = true)\n",
      " |-- Borough_DO: string (nullable = true)\n",
      " |-- Zone_DO: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- dow: integer (nullable = true)\n",
      " |-- quarter: integer (nullable = true)\n",
      " |-- dow_long: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day_time: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- bins_duration: string (nullable = true)\n",
      " |-- speed: double (nullable = true)\n",
      " |-- bins_distance: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_model.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_var = [\n",
    " 'trip_distance',\n",
    " 'extra',\n",
    " 'tip_amount',\n",
    " 'tolls_amount',\n",
    " 'improvement_surcharge',\n",
    " 'total_amount',\n",
    " 'congestion_surcharge',\n",
    " 'speed',\n",
    " 'duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = df_model.select(corr_var)\n",
    "\n",
    "col_names = corr_data.columns\n",
    "features = corr_data.rdd.map(lambda row: row[0:])\n",
    "corr_mat=Statistics.corr(features, method=\"pearson\")\n",
    "corr_df = pd.DataFrame(corr_mat)\n",
    "corr_df.index, corr_df.columns = col_names, col_names\n",
    "\n",
    "# print(corr_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>extra</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>speed</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trip_distance</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.055338</td>\n",
       "      <td>0.505426</td>\n",
       "      <td>0.598967</td>\n",
       "      <td>-0.054412</td>\n",
       "      <td>0.925235</td>\n",
       "      <td>-0.151918</td>\n",
       "      <td>0.658451</td>\n",
       "      <td>0.782197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra</th>\n",
       "      <td>-0.055338</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005800</td>\n",
       "      <td>-0.070279</td>\n",
       "      <td>0.035803</td>\n",
       "      <td>-0.031688</td>\n",
       "      <td>-0.004035</td>\n",
       "      <td>-0.015334</td>\n",
       "      <td>-0.043530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tip_amount</th>\n",
       "      <td>0.505426</td>\n",
       "      <td>-0.005800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.418334</td>\n",
       "      <td>0.031372</td>\n",
       "      <td>0.679567</td>\n",
       "      <td>0.108017</td>\n",
       "      <td>0.286834</td>\n",
       "      <td>0.451582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolls_amount</th>\n",
       "      <td>0.598967</td>\n",
       "      <td>-0.070279</td>\n",
       "      <td>0.418334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.017525</td>\n",
       "      <td>0.653784</td>\n",
       "      <td>-0.024693</td>\n",
       "      <td>0.395615</td>\n",
       "      <td>0.437976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <td>-0.054412</td>\n",
       "      <td>0.035803</td>\n",
       "      <td>0.031372</td>\n",
       "      <td>-0.017525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034669</td>\n",
       "      <td>0.090917</td>\n",
       "      <td>-0.032874</td>\n",
       "      <td>-0.061120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_amount</th>\n",
       "      <td>0.925235</td>\n",
       "      <td>-0.031688</td>\n",
       "      <td>0.679567</td>\n",
       "      <td>0.653784</td>\n",
       "      <td>-0.034669</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011055</td>\n",
       "      <td>0.515663</td>\n",
       "      <td>0.839491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <td>-0.151918</td>\n",
       "      <td>-0.004035</td>\n",
       "      <td>0.108017</td>\n",
       "      <td>-0.024693</td>\n",
       "      <td>0.090917</td>\n",
       "      <td>-0.011055</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.182554</td>\n",
       "      <td>-0.059582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speed</th>\n",
       "      <td>0.658451</td>\n",
       "      <td>-0.015334</td>\n",
       "      <td>0.286834</td>\n",
       "      <td>0.395615</td>\n",
       "      <td>-0.032874</td>\n",
       "      <td>0.515663</td>\n",
       "      <td>-0.182554</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.188027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>0.782197</td>\n",
       "      <td>-0.043530</td>\n",
       "      <td>0.451582</td>\n",
       "      <td>0.437976</td>\n",
       "      <td>-0.061120</td>\n",
       "      <td>0.839491</td>\n",
       "      <td>-0.059582</td>\n",
       "      <td>0.188027</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       trip_distance     extra  tip_amount  tolls_amount  \\\n",
       "trip_distance               1.000000 -0.055338    0.505426      0.598967   \n",
       "extra                      -0.055338  1.000000   -0.005800     -0.070279   \n",
       "tip_amount                  0.505426 -0.005800    1.000000      0.418334   \n",
       "tolls_amount                0.598967 -0.070279    0.418334      1.000000   \n",
       "improvement_surcharge      -0.054412  0.035803    0.031372     -0.017525   \n",
       "total_amount                0.925235 -0.031688    0.679567      0.653784   \n",
       "congestion_surcharge       -0.151918 -0.004035    0.108017     -0.024693   \n",
       "speed                       0.658451 -0.015334    0.286834      0.395615   \n",
       "duration                    0.782197 -0.043530    0.451582      0.437976   \n",
       "\n",
       "                       improvement_surcharge  total_amount  \\\n",
       "trip_distance                      -0.054412      0.925235   \n",
       "extra                               0.035803     -0.031688   \n",
       "tip_amount                          0.031372      0.679567   \n",
       "tolls_amount                       -0.017525      0.653784   \n",
       "improvement_surcharge               1.000000     -0.034669   \n",
       "total_amount                       -0.034669      1.000000   \n",
       "congestion_surcharge                0.090917     -0.011055   \n",
       "speed                              -0.032874      0.515663   \n",
       "duration                           -0.061120      0.839491   \n",
       "\n",
       "                       congestion_surcharge     speed  duration  \n",
       "trip_distance                     -0.151918  0.658451  0.782197  \n",
       "extra                             -0.004035 -0.015334 -0.043530  \n",
       "tip_amount                         0.108017  0.286834  0.451582  \n",
       "tolls_amount                      -0.024693  0.395615  0.437976  \n",
       "improvement_surcharge              0.090917 -0.032874 -0.061120  \n",
       "total_amount                      -0.011055  0.515663  0.839491  \n",
       "congestion_surcharge               1.000000 -0.182554 -0.059582  \n",
       "speed                             -0.182554  1.000000  0.188027  \n",
       "duration                          -0.059582  0.188027  1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df\n",
    "#with total amount is very correlated(positive) trip distance, duration, tip amount, tolls amount, and speed.\n",
    "#between them: speed with trip_distance have a positive correlation(it is expected because speed  was created with trip distance)\n",
    "#but there are not multicolinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some information of categorical\n",
    "- additional to the bussiness questions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>payment_type</th><th>avg(total_amount)</th></tr>\n",
       "<tr><td>3</td><td>18.839148980207245</td></tr>\n",
       "<tr><td>5</td><td>16.153259203169082</td></tr>\n",
       "<tr><td>1</td><td>19.440214191482696</td></tr>\n",
       "<tr><td>4</td><td>18.459082389825337</td></tr>\n",
       "<tr><td>2</td><td>15.277134558823871</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+------------------+\n",
       "|payment_type| avg(total_amount)|\n",
       "+------------+------------------+\n",
       "|           3|18.839148980207245|\n",
       "|           5|16.153259203169082|\n",
       "|           1|19.440214191482696|\n",
       "|           4|18.459082389825337|\n",
       "|           2|15.277134558823871|\n",
       "+------------+------------------+"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"payment_type\").agg(\n",
    "      F.avg(\"total_amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>day_time</th><th>avg(total_amount)</th></tr>\n",
       "<tr><td>afternoon</td><td>17.92181650176273</td></tr>\n",
       "<tr><td>morning</td><td>17.509077209948025</td></tr>\n",
       "<tr><td>late night</td><td>18.907289130422285</td></tr>\n",
       "<tr><td>evening</td><td>18.323967500609637</td></tr>\n",
       "<tr><td>early morning</td><td>19.274203122245275</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------+------------------+\n",
       "|     day_time| avg(total_amount)|\n",
       "+-------------+------------------+\n",
       "|    afternoon| 17.92181650176273|\n",
       "|      morning|17.509077209948025|\n",
       "|   late night|18.907289130422285|\n",
       "|      evening|18.323967500609637|\n",
       "|early morning|19.274203122245275|\n",
       "+-------------+------------------+"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"day_time\").agg(\n",
    "      F.avg(\"total_amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>RatecodeID</th><th>avg(total_amount)</th></tr>\n",
       "<tr><td>3</td><td>45.28260809904577</td></tr>\n",
       "<tr><td>5</td><td>37.66927490512147</td></tr>\n",
       "<tr><td>6</td><td>10.712174161620762</td></tr>\n",
       "<tr><td>1</td><td>17.164054550549952</td></tr>\n",
       "<tr><td>4</td><td>58.662294953959254</td></tr>\n",
       "<tr><td>2</td><td>68.06670469709013</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+------------------+\n",
       "|RatecodeID| avg(total_amount)|\n",
       "+----------+------------------+\n",
       "|         3| 45.28260809904577|\n",
       "|         5| 37.66927490512147|\n",
       "|         6|10.712174161620762|\n",
       "|         1|17.164054550549952|\n",
       "|         4|58.662294953959254|\n",
       "|         2| 68.06670469709013|\n",
       "+----------+------------------+"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"RatecodeID\").agg(\n",
    "      F.avg(\"total_amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>store_and_fwd_flag</th><th>avg(total_amount)</th></tr>\n",
       "<tr><td>Y</td><td>19.41564811858532</td></tr>\n",
       "<tr><td>N</td><td>18.235599580778963</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------------+------------------+\n",
       "|store_and_fwd_flag| avg(total_amount)|\n",
       "+------------------+------------------+\n",
       "|                 Y| 19.41564811858532|\n",
       "|                 N|18.235599580778963|\n",
       "+------------------+------------------+"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"store_and_fwd_flag\").agg(\n",
    "      F.avg(\"total_amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>bins_duration</th><th>avg(total_amount)</th></tr>\n",
       "<tr><td>long1</td><td>28.253768081241702</td></tr>\n",
       "<tr><td>long2</td><td>47.681962778953576</td></tr>\n",
       "<tr><td>short1</td><td>9.143770304875401</td></tr>\n",
       "<tr><td>short2</td><td>11.693697397774985</td></tr>\n",
       "<tr><td>middle</td><td>17.378305928837285</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------+------------------+\n",
       "|bins_duration| avg(total_amount)|\n",
       "+-------------+------------------+\n",
       "|        long1|28.253768081241702|\n",
       "|        long2|47.681962778953576|\n",
       "|       short1| 9.143770304875401|\n",
       "|       short2|11.693697397774985|\n",
       "|       middle|17.378305928837285|\n",
       "+-------------+------------------+"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"bins_duration\").agg(\n",
    "      F.avg(\"total_amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>bins_distance</th><th>avg(total_amount)</th></tr>\n",
       "<tr><td>long1</td><td>126.13791769742966</td></tr>\n",
       "<tr><td>long2</td><td>172.93500002692727</td></tr>\n",
       "<tr><td>short1</td><td>14.224050339614044</td></tr>\n",
       "<tr><td>short2</td><td>40.639347451623145</td></tr>\n",
       "<tr><td>middle</td><td>71.58374561213907</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------+------------------+\n",
       "|bins_distance| avg(total_amount)|\n",
       "+-------------+------------------+\n",
       "|        long1|126.13791769742966|\n",
       "|        long2|172.93500002692727|\n",
       "|       short1|14.224050339614044|\n",
       "|       short2|40.639347451623145|\n",
       "|       middle| 71.58374561213907|\n",
       "+-------------+------------------+"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"bins_distance\").agg(\n",
    "      F.avg(\"total_amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>trip_type</th><th>avg(total_amount)</th></tr>\n",
       "<tr><td>1</td><td>15.147609094336952</td></tr>\n",
       "<tr><td>no</td><td>18.472742191931236</td></tr>\n",
       "<tr><td>2</td><td>26.552489302848482</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+------------------+\n",
       "|trip_type| avg(total_amount)|\n",
       "+---------+------------------+\n",
       "|        1|15.147609094336952|\n",
       "|       no|18.472742191931236|\n",
       "|        2|26.552489302848482|\n",
       "+---------+------------------+"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"trip_type\").agg(\n",
    "      F.avg(\"total_amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>taxi_type</th><th>avg(total_amount)</th></tr>\n",
       "<tr><td>green</td><td>15.508819398431637</td></tr>\n",
       "<tr><td>yellow</td><td>18.472742191931236</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+------------------+\n",
       "|taxi_type| avg(total_amount)|\n",
       "+---------+------------------+\n",
       "|    green|15.508819398431637|\n",
       "|   yellow|18.472742191931236|\n",
       "+---------+------------------+"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"taxi_type\").agg(\n",
    "      F.avg(\"total_amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>avg(total_amount)</th></tr>\n",
       "<tr><td>1</td><td>18.514978795375693</td></tr>\n",
       "<tr><td>2</td><td>18.221892943940382</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+------------------+\n",
       "|VendorID| avg(total_amount)|\n",
       "+--------+------------------+\n",
       "|       1|18.514978795375693|\n",
       "|       2|18.221892943940382|\n",
       "+--------+------------------+"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"VendorID\").agg(\n",
    "      F.avg(\"total_amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>avg(total_amount)</th></tr>\n",
       "<tr><td>2020</td><td>17.354182974664212</td></tr>\n",
       "<tr><td>2019</td><td>18.50764610209183</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+------------------+\n",
       "|year| avg(total_amount)|\n",
       "+----+------------------+\n",
       "|2020|17.354182974664212|\n",
       "|2019| 18.50764610209183|\n",
       "+----+------------------+"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"year\").agg(\n",
    "      F.avg(\"total_amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>month</th><th>avg(total_amount)</th></tr>\n",
       "<tr><td>7</td><td>18.50505163977245</td></tr>\n",
       "<tr><td>11</td><td>18.186317858789305</td></tr>\n",
       "<tr><td>3</td><td>18.304369230534444</td></tr>\n",
       "<tr><td>8</td><td>18.43386836929054</td></tr>\n",
       "<tr><td>5</td><td>18.746270334225652</td></tr>\n",
       "<tr><td>6</td><td>18.826424355698272</td></tr>\n",
       "<tr><td>9</td><td>18.601822796200995</td></tr>\n",
       "<tr><td>1</td><td>16.811491006470014</td></tr>\n",
       "<tr><td>10</td><td>18.425298701770906</td></tr>\n",
       "<tr><td>4</td><td>18.438268491909742</td></tr>\n",
       "<tr><td>12</td><td>18.310463297928457</td></tr>\n",
       "<tr><td>2</td><td>17.960086654796715</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+------------------+\n",
       "|month| avg(total_amount)|\n",
       "+-----+------------------+\n",
       "|    7| 18.50505163977245|\n",
       "|   11|18.186317858789305|\n",
       "|    3|18.304369230534444|\n",
       "|    8| 18.43386836929054|\n",
       "|    5|18.746270334225652|\n",
       "|    6|18.826424355698272|\n",
       "|    9|18.601822796200995|\n",
       "|    1|16.811491006470014|\n",
       "|   10|18.425298701770906|\n",
       "|    4|18.438268491909742|\n",
       "|   12|18.310463297928457|\n",
       "|    2|17.960086654796715|\n",
       "+-----+------------------+"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"month\").agg(\n",
    "      F.avg(\"total_amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>dow_long</th><th>avg(total_amount)</th></tr>\n",
       "<tr><td>Wednesday</td><td>18.252978752192085</td></tr>\n",
       "<tr><td>Tuesday</td><td>18.141381296582548</td></tr>\n",
       "<tr><td>Friday</td><td>18.292258007219125</td></tr>\n",
       "<tr><td>Thursday</td><td>18.50573191801035</td></tr>\n",
       "<tr><td>Saturday</td><td>17.58065442072873</td></tr>\n",
       "<tr><td>Monday</td><td>18.411452331658854</td></tr>\n",
       "<tr><td>Sunday</td><td>18.51102844861624</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+------------------+\n",
       "| dow_long| avg(total_amount)|\n",
       "+---------+------------------+\n",
       "|Wednesday|18.252978752192085|\n",
       "|  Tuesday|18.141381296582548|\n",
       "|   Friday|18.292258007219125|\n",
       "| Thursday| 18.50573191801035|\n",
       "| Saturday| 17.58065442072873|\n",
       "|   Monday|18.411452331658854|\n",
       "|   Sunday| 18.51102844861624|\n",
       "+---------+------------------+"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"dow_long\").agg(\n",
    "      F.avg(\"total_amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>quarter</th><th>avg(total_amount)</th></tr>\n",
       "<tr><td>1</td><td>17.72636673479108</td></tr>\n",
       "<tr><td>3</td><td>18.516759928984605</td></tr>\n",
       "<tr><td>4</td><td>18.309439879640077</td></tr>\n",
       "<tr><td>2</td><td>18.67016935986904</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+------------------+\n",
       "|quarter| avg(total_amount)|\n",
       "+-------+------------------+\n",
       "|      1| 17.72636673479108|\n",
       "|      3|18.516759928984605|\n",
       "|      4|18.309439879640077|\n",
       "|      2| 18.67016935986904|\n",
       "+-------+------------------+"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"quarter\").agg(\n",
    "      F.avg(\"total_amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>mta_tax</th><th>avg(total_amount)</th></tr>\n",
       "<tr><td>0.0</td><td>36.55852516328567</td></tr>\n",
       "<tr><td>0.5</td><td>18.193904417397956</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+------------------+\n",
       "|mta_tax| avg(total_amount)|\n",
       "+-------+------------------+\n",
       "|    0.0| 36.55852516328567|\n",
       "|    0.5|18.193904417397956|\n",
       "+-------+------------------+"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"mta_tax\").agg(\n",
    "      F.avg(\"total_amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>passenger_count</th><th>avg(total_amount)</th></tr>\n",
       "<tr><td>1</td><td>18.16574229904865</td></tr>\n",
       "<tr><td>6</td><td>18.16736194469376</td></tr>\n",
       "<tr><td>3</td><td>18.355807092514326</td></tr>\n",
       "<tr><td>5</td><td>18.199312842904426</td></tr>\n",
       "<tr><td>4</td><td>18.408944978409576</td></tr>\n",
       "<tr><td>2</td><td>18.558328005861878</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------+------------------+\n",
       "|passenger_count| avg(total_amount)|\n",
       "+---------------+------------------+\n",
       "|              1| 18.16574229904865|\n",
       "|              6| 18.16736194469376|\n",
       "|              3|18.355807092514326|\n",
       "|              5|18.199312842904426|\n",
       "|              4|18.408944978409576|\n",
       "|              2|18.558328005861878|\n",
       "+---------------+------------------+"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"passenger_count\").agg(\n",
    "      F.avg(\"total_amount\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking the total fare amount for the categories of the categorical variables, it could be realised that payment type, day time, store_fw_flag  and vendorID have similar total amount per class. But, ratecodeID have differences, been number 2 (Airport) the most expensive. Also, bins duration and bins distance have different total amount per category.  Besides, dispatch trips are more expensive and yellow taxis. Mta_tax also have different total amount and for passenger count there are not a difference.\n",
    "\n",
    "For dates variables, there are not a high diference in total amount (years, quarter, months and day of the week).\n",
    "\n",
    "Also, it is important to see that having small categories for each string type makes creating one-hot encoding a suitable pre-processing step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "- Linear Regression\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting colums\n",
    "- first models, all the raw columns were selected and daytime instead of hours\n",
    "- second, considering the above analysis and the feature importance of the first models-first set of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Selection of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selection of columns\n",
    "cols_list = ['VendorID','passenger_count','trip_distance','RatecodeID','store_and_fwd_flag','payment_type','extra','mta_tax','tip_amount',\n",
    " 'tolls_amount','improvement_surcharge','total_amount','congestion_surcharge','taxi_type','trip_type','Borough_PU','Borough_DO',\n",
    " 'year','quarter','dow_long','month','day_time','duration','speed']\n",
    "\n",
    "df_model = df_model.select(cols_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['payment_type','day_time','RatecodeID', 'year','month', 'VendorID', 'store_and_fwd_flag','taxi_type','trip_type',\n",
    "            'Borough_PU','Borough_DO', 'dow_long', 'passenger_count','mta_tax', 'quarter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['congestion_surcharge','improvement_surcharge','extra', 'tolls_amount', 'tip_amount', 'trip_distance','duration', 'speed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform categorical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = []\n",
    "for cat_col in cat_cols:\n",
    "    col_indexer = StringIndexer(inputCol=cat_col, outputCol=f\"{cat_col}_ind\")\n",
    "    col_encoder = OneHotEncoderEstimator(inputCols=[f\"{cat_col}_ind\"], outputCols=[f\"{cat_col}_ohe\"])\n",
    "    stages += [col_indexer, col_encoder]\n",
    "    \n",
    "cat_cols_ohe = [f\"{cat_col}_ohe\" for cat_col in cat_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector assemble for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features\n",
    "assembler = VectorAssembler(inputCols=cat_cols_ohe + num_cols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target change the name a label \n",
    "df_model = df_model.withColumnRenamed(\"total_amount\", \"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = pipeline.fit(df_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pipeline_model.transform(df_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.show of +-----+--------------------+\n",
       "|label|            features|\n",
       "+-----+--------------------+\n",
       "| 13.8|(63,[1,4,8,13,16,...|\n",
       "| 14.3|(63,[0,6,8,13,14,...|\n",
       "| 18.3|(63,[1,7,8,13,16,...|\n",
       "| 12.3|(63,[0,6,8,13,14,...|\n",
       "| 16.3|(63,[1,4,8,13,16,...|\n",
       "| 10.8|(63,[1,6,8,13,14,...|\n",
       "|18.95|(63,[0,4,8,13,16,...|\n",
       "| 11.8|(63,[0,6,8,13,14,...|\n",
       "| 22.8|(63,[1,4,8,13,16,...|\n",
       "| 14.8|(63,[1,6,8,13,14,...|\n",
       "|15.39|(63,[0,8,13,16,25...|\n",
       "|15.96|(63,[0,5,8,13,14,...|\n",
       "| 16.8|(63,[1,4,8,13,16,...|\n",
       "|19.32|(63,[0,6,8,13,14,...|\n",
       "| 16.8|(63,[1,4,8,13,16,...|\n",
       "| 14.3|(63,[1,6,8,13,14,...|\n",
       "| 30.0|(63,[0,4,8,13,16,...|\n",
       "|15.96|(63,[0,6,8,13,14,...|\n",
       "|29.96|(63,[0,4,10,13,16...|\n",
       "|  9.8|(63,[1,5,8,13,14,...|\n",
       "+-----+--------------------+\n",
       "only showing top 20 rows\n",
       ">"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selectng the two columns that we need to pyspark\n",
    "df_model.select(['label', 'features']).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test for the last 3 months of 2020\n",
    "train_data = df_model.where((df_model.year ==2019) | (df_model.year == 2020) & (df_model.month <10))\n",
    "test_data = df_model.where((df_model.year == 2020) & (df_model.month >9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69971105"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3326308"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(featuresCol=\"features\",\\\n",
    "                            labelCol=\"label\", seed = 12 )\n",
    "                           \n",
    "model = rfr.fit(train_data)\n",
    "predictions_rfr_train = model.transform(train_data)\n",
    "predictions_rfr_test = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "\n",
    "# Define LinearRegression algorithm \n",
    "glr = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\",\\\n",
    "                                  maxIter=10, regParam=0.3, featuresCol=\"features\",\\\n",
    "                                  labelCol=\"label\")\n",
    "                           \n",
    "model2 = glr.fit(train_data)\n",
    "predictions_glr_train = model2.transform(train_data)\n",
    "predictions_glr_test = model2.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not used finally, very long\n",
    "#print(\"Coefficients: \" + str(model2.coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2.summary #not used, very long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance: RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE is used as evaluation metric\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\",\\\n",
    "                                labelCol=\"label\",\\\n",
    "                                metricName =\"rmse\")\n",
    "RMSE_rfr_test= evaluator.evaluate(predictions_rfr_test)\n",
    "RMSE_rfr_train = evaluator.evaluate(predictions_rfr_train)\n",
    "\n",
    "RMSE_glr_test= evaluator.evaluate(predictions_glr_test)\n",
    "RMSE_glr_train = evaluator.evaluate(predictions_glr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Root Mean Squared Error (RMSE) on train data = 2.85931\n",
      "Root Mean Squared Error (RMSE) on test data = 2.60685\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest\")\n",
    "print(\"Root Mean Squared Error (RMSE) on train data = %g\" % RMSE_rfr_train)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % RMSE_rfr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Root Mean Squared Error (RMSE) on train data = 2.483\n",
      "Root Mean Squared Error (RMSE) on test data = 2.01799\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression\")\n",
    "print(\"Root Mean Squared Error (RMSE) on train data = %g\" % RMSE_glr_train)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % RMSE_glr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE is helpful to compare between models. Looking above, Linear Regression performs better (lower error) than Random Forest, but, they are similar.\n",
    "\n",
    "Because RMSE is in units of the outcome, alone is meaningless. Therefore, one form to know if we are getting a good performance is to compare it with the description of the actual target value. After comparison with the standard deviation in the cleaning part above, the RMSE is lower, therefore looks good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(63, {0: 0.003, 1: 0.0013, 6: 0.0, 7: 0.0, 8: 0.0151, 9: 0.0391, 10: 0.0011, 11: 0.0, 12: 0.0, 16: 0.0, 25: 0.0, 27: 0.0005, 28: 0.0006, 30: 0.0218, 31: 0.011, 32: 0.0, 35: 0.0101, 36: 0.0004, 37: 0.0002, 38: 0.0, 39: 0.0, 45: 0.0, 51: 0.0002, 55: 0.0008, 56: 0.0002, 57: 0.0003, 58: 0.0527, 59: 0.1264, 60: 0.3939, 61: 0.2799, 62: 0.0413})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractFeatureImp(featureImp, dataset, featuresCol):\n",
    "    list_extract = []\n",
    "    for i in dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"]:\n",
    "        list_extract = list_extract + dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"][i]\n",
    "    varlist = pd.DataFrame(list_extract)\n",
    "    varlist['score'] = varlist['idx'].apply(lambda x: featureImp[x])\n",
    "    return(varlist.sort_values('score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>trip_distance</td>\n",
       "      <td>0.393903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>61</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.279850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>tip_amount</td>\n",
       "      <td>0.126414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>tolls_amount</td>\n",
       "      <td>0.052688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>62</td>\n",
       "      <td>speed</td>\n",
       "      <td>0.041256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>RatecodeID_ohe_2</td>\n",
       "      <td>0.039111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>30</td>\n",
       "      <td>Borough_PU_ohe_Manhattan</td>\n",
       "      <td>0.021844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>RatecodeID_ohe_1</td>\n",
       "      <td>0.015110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>31</td>\n",
       "      <td>Borough_PU_ohe_Queens</td>\n",
       "      <td>0.011029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>35</td>\n",
       "      <td>Borough_DO_ohe_Manhattan</td>\n",
       "      <td>0.010059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    idx                      name     score\n",
       "5    60             trip_distance  0.393903\n",
       "6    61                  duration  0.279850\n",
       "4    59                tip_amount  0.126414\n",
       "3    58              tolls_amount  0.052688\n",
       "7    62                     speed  0.041256\n",
       "17    9          RatecodeID_ohe_2  0.039111\n",
       "38   30  Borough_PU_ohe_Manhattan  0.021844\n",
       "16    8          RatecodeID_ohe_1  0.015110\n",
       "39   31     Borough_PU_ohe_Queens  0.011029\n",
       "43   35  Borough_DO_ohe_Manhattan  0.010059"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExtractFeatureImp(model.featureImportances, df_model, \"features\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing manually parameters of Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxDepth: Maximum depth of the tree. (Nonnegative) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. (default: 5)\n",
      "maxBins: Max number of bins for discretizing continuous features.  Must be at least 2 and at least number of categories for any categorical feature. (default: 32)\n",
      "numTrees: Number of trees to train (at least 1) (default: 20)\n"
     ]
    }
   ],
   "source": [
    "#default parameters for random forest model\n",
    "print(model.explainParam(\"maxDepth\")) #shorter is more generalizable\n",
    "print(model.explainParam(\"maxBins\"))  #more bins more time processing but more exactly\n",
    "print(model.explainParam(\"numTrees\")) #change trees to make the final \"votation\"\n",
    "#maxDepth=5, maxBins=32,numTrees=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr2 = RandomForestRegressor(featuresCol=\"features\",\\\n",
    "                            labelCol=\"label\", numTrees = 10, seed =12, \\\n",
    "                           maxDepth = 10, maxBins = 10)\n",
    "rfr3 = RandomForestRegressor(featuresCol=\"features\",\\\n",
    "                            labelCol=\"label\", numTrees = 10, seed =12, \\\n",
    "                           maxDepth = 5, maxBins = 10)\n",
    "rfr4 = RandomForestRegressor(featuresCol=\"features\",\\\n",
    "                            labelCol=\"label\", numTrees = 10, seed =12, \\\n",
    "                           maxDepth = 10, maxBins = 20)\n",
    "                           \n",
    "model_rfr2 = rfr2.fit(train_data)\n",
    "predictions_rfr_train_2 = model_rfr2.transform(train_data)\n",
    "predictions_rfr_test_2 = model_rfr2.transform(test_data)\n",
    "\n",
    "model_rfr3 = rfr3.fit(train_data)\n",
    "predictions_rfr_train_3 = model_rfr3.transform(train_data)\n",
    "predictions_rfr_test_3 = model_rfr3.transform(test_data)\n",
    "\n",
    "model_rfr4 = rfr4.fit(train_data)\n",
    "predictions_rfr_train_4 = model_rfr4.transform(train_data)\n",
    "predictions_rfr_test_4 = model_rfr4.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N1\n",
      "2.7479517493487244\n",
      "2.5303145412758834\n",
      "N2\n",
      "3.5440389751293515\n",
      "3.138203003293098\n",
      "N3\n",
      "2.1358847611212157\n",
      "2.0237583116045674\n"
     ]
    }
   ],
   "source": [
    "#RMSE\n",
    "print(\"N1\")\n",
    "print( evaluator.evaluate(predictions_rfr_train_2))\n",
    "print(evaluator.evaluate(predictions_rfr_test_2))\n",
    "\n",
    "print(\"N2\")\n",
    "print( evaluator.evaluate(predictions_rfr_train_3))\n",
    "print(evaluator.evaluate(predictions_rfr_test_3))\n",
    "\n",
    "print(\"N3\")\n",
    "print( evaluator.evaluate(predictions_rfr_train_4))\n",
    "print(evaluator.evaluate(predictions_rfr_test_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>trip_distance</td>\n",
       "      <td>0.417131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>61</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.259664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>tip_amount</td>\n",
       "      <td>0.100575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>tolls_amount</td>\n",
       "      <td>0.058646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>62</td>\n",
       "      <td>speed</td>\n",
       "      <td>0.038316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>RatecodeID_ohe_2</td>\n",
       "      <td>0.033874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>35</td>\n",
       "      <td>Borough_DO_ohe_Manhattan</td>\n",
       "      <td>0.023240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>31</td>\n",
       "      <td>Borough_PU_ohe_Queens</td>\n",
       "      <td>0.019982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>RatecodeID_ohe_1</td>\n",
       "      <td>0.017043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>payment_type_ohe_1</td>\n",
       "      <td>0.007588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    idx                      name     score\n",
       "5    60             trip_distance  0.417131\n",
       "6    61                  duration  0.259664\n",
       "4    59                tip_amount  0.100575\n",
       "3    58              tolls_amount  0.058646\n",
       "7    62                     speed  0.038316\n",
       "17    9          RatecodeID_ohe_2  0.033874\n",
       "43   35  Borough_DO_ohe_Manhattan  0.023240\n",
       "39   31     Borough_PU_ohe_Queens  0.019982\n",
       "16    8          RatecodeID_ohe_1  0.017043\n",
       "8     0        payment_type_ohe_1  0.007588"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExtractFeatureImp(model_rfr4.featureImportances, df_model, \"features\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last tuning for RF had a performance similar to the linear regresion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search (it was not done because it takes a long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #using others parameters\n",
    "\n",
    "# from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# rfr = RandomForestRegressor(featuresCol=\"features\",\\\n",
    "#                             labelCol=\"label\" , numTrees = 10, seed =12)\n",
    "\n",
    "# evaluator = RegressionEvaluator(predictionCol=\"prediction\",\\\n",
    "#                                 labelCol=\"label\",\\\n",
    "#                                 metricName =\"rmse\")\n",
    "\n",
    "# paramGrid = (ParamGridBuilder()\n",
    "#              .addGrid(rfr.maxDepth, [5,10])\n",
    "#              .addGrid(rfr.maxBins, [10, 20])\n",
    "#   #           .addGrid(rfr.numTrees, [10])\n",
    "#              .build())\n",
    "\n",
    "# # paramGrid = ParamGridBuilder() \\\n",
    "# #     .addGrid(rfr.numTrees, [int(x) for x in np.linspace(start = 10, stop = 50, num = 3)]) \\\n",
    "# #     .addGrid(rfr.maxDepth, [int(x) for x in np.linspace(start = 5, stop = 25, num = 3)]) \\\n",
    "# #     .addGrid(rfr.maxBins, [10,20,50]) \\\n",
    "# #     .build()\n",
    "\n",
    "# cv = CrossValidator(estimator=rfr,\n",
    "#                           estimatorParamMaps=paramGrid,\n",
    "#                           evaluator=evaluator,\n",
    "#                           numFolds=3)  \n",
    "\n",
    "# cvModel = cv.fit(train_data)\n",
    "\n",
    "# predictions = cvModel.transform(test_data)\n",
    "# cm = predictions.select(\"prediction\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse = evaluator.evaluate(predictions)\n",
    "# print(\"RMSE on our test set: %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestPipeline = cvModel.bestModel\n",
    "# bestModel = bestPipeline.stages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #BEST HYPERPARAMETERS\n",
    "\n",
    "# print('numTrees - ', bestModel.getNumTrees)\n",
    "# print('maxDepth - ', bestModel.getOrDefault('maxDepth'))\n",
    "# print('maxBins - ', bestModel.getOrDefault('maxBins'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #feature importance\n",
    "# importances = bestModel.featureImportances\n",
    "\n",
    "# x_values = list(range(len(importances)))\n",
    "# #x_values.orderBy([\"value\", \"rank\"], ascending=[1, 1])\n",
    "\n",
    "# plt.bar(x_values, importances, orientation = 'vertical')\n",
    "# plt.xticks(x_values, feature_list, rotation=90)\n",
    "# plt.ylabel('Importance')\n",
    "# plt.xlabel('Feature')\n",
    "# plt.title('Feature Importances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second selection of variables\n",
    "- given that from the correlation part and the feature importance part above, duration and distance are esential, they were kept as variables (the running time was not too long so the bins were not useful). Only the 10 important features of the RF were selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df\n",
    "df_model = df_model.drop(\"fare_amount\", \"ehail_fee\", \"pickup_datetime\", \"dropoff_datetime\", \"PULocationID\", \"DOLocationID\", \"Zone_PU\", \"Zone_PU\", \"av_paid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selection of columns\n",
    "cols_list = ['RatecodeID','tip_amount','trip_distance', 'duration',\n",
    " 'tolls_amount','total_amount','Borough_PU','Borough_DO',\n",
    " 'year','month','speed', 'payment_type']\n",
    "\n",
    "df_model = df_model.select(cols_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical data\n",
    "cat_cols = ['RatecodeID', 'year','month','payment_type',\n",
    "            'Borough_PU','Borough_DO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical data\n",
    "num_cols = ['tolls_amount', 'tip_amount', 'speed', 'trip_distance','duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform categorical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = []\n",
    "for cat_col in cat_cols:\n",
    "    col_indexer = StringIndexer(inputCol=cat_col, outputCol=f\"{cat_col}_ind\")\n",
    "    col_encoder = OneHotEncoderEstimator(inputCols=[f\"{cat_col}_ind\"], outputCols=[f\"{cat_col}_ohe\"])\n",
    "    stages += [col_indexer, col_encoder]\n",
    "    \n",
    "cat_cols_ohe = [f\"{cat_col}_ohe\" for cat_col in cat_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector assemble for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features\n",
    "assembler = VectorAssembler(inputCols=cat_cols_ohe + num_cols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target change the name a label \n",
    "df_model = df_model.withColumnRenamed(\"total_amount\", \"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = pipeline.fit(df_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pipeline_model.transform(df_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.show of +-----+--------------------+\n",
       "|label|            features|\n",
       "+-----+--------------------+\n",
       "| 13.8|(36,[0,5,8,18,22,...|\n",
       "| 14.3|(36,[0,5,6,17,21,...|\n",
       "| 18.3|(36,[0,5,8,18,22,...|\n",
       "| 12.3|(36,[0,5,6,17,21,...|\n",
       "| 16.3|(36,[0,5,8,18,22,...|\n",
       "| 10.8|(36,[0,5,6,18,21,...|\n",
       "|18.95|(36,[0,5,8,17,22,...|\n",
       "| 11.8|(36,[0,5,6,17,21,...|\n",
       "| 22.8|(36,[0,5,8,18,22,...|\n",
       "| 14.8|(36,[0,5,6,18,21,...|\n",
       "|15.39|(36,[0,5,8,17,22,...|\n",
       "|15.96|(36,[0,5,6,17,21,...|\n",
       "| 16.8|(36,[0,5,8,18,22,...|\n",
       "|19.32|(36,[0,5,6,17,21,...|\n",
       "| 16.8|(36,[0,5,8,18,22,...|\n",
       "| 14.3|(36,[0,5,6,18,21,...|\n",
       "| 30.0|(36,[0,5,8,17,22,...|\n",
       "|15.96|(36,[0,5,6,17,21,...|\n",
       "|29.96|(36,[2,5,8,17,22,...|\n",
       "|  9.8|(36,[0,5,6,18,21,...|\n",
       "+-----+--------------------+\n",
       "only showing top 20 rows\n",
       ">"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selectng the two columns that we need to pyspark\n",
    "df_model.select(['label', 'features']).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#where for the last 3 months of 2020\n",
    "train_data = df_model.where((df_model.year ==2019) | (df_model.year == 2020) & (df_model.month <10))\n",
    "test_data = df_model.where((df_model.year == 2020) & (df_model.month >9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69971105"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3326308"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(featuresCol=\"features\",\\\n",
    "                            labelCol=\"label\", seed = 12 )\n",
    "#numTrees=10,     \n",
    "\n",
    "model3 = rfr.fit(train_data)\n",
    "predictions_rfr_train2 = model3.transform(train_data)\n",
    "predictions_rfr_test2 = model3.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearRegression class\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "\n",
    "# Define LinearRegression algorithm \n",
    "glr = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\",\\\n",
    "                                  maxIter=10, regParam=0.3, featuresCol=\"features\",\\\n",
    "                                  labelCol=\"label\")\n",
    "                           \n",
    "model4 = glr.fit(train_data)\n",
    "predictions_glr_train2 = model4.transform(train_data)\n",
    "predictions_glr_test2 = model4.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Coefficients: \" + str(model2.coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model4.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE is used as evaluation metric\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\",\\\n",
    "                                labelCol=\"label\",\\\n",
    "                                metricName =\"rmse\")\n",
    "RMSE_rfr_test2= evaluator.evaluate(predictions_rfr_test2)\n",
    "RMSE_rfr_train2 = evaluator.evaluate(predictions_rfr_train2)\n",
    "\n",
    "RMSE_glr_test2= evaluator.evaluate(predictions_glr_test2)\n",
    "RMSE_glr_train2 = evaluator.evaluate(predictions_glr_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Root Mean Squared Error (RMSE) on train data = 2.90293\n",
      "Root Mean Squared Error (RMSE) on test data = 2.68506\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest\")\n",
    "print(\"Root Mean Squared Error (RMSE) on train data = %g\" % RMSE_rfr_train2)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % RMSE_rfr_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Root Mean Squared Error (RMSE) on train data = 2.642\n",
      "Root Mean Squared Error (RMSE) on test data = 2.24827\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression\")\n",
    "print(\"Root Mean Squared Error (RMSE) on train data = %g\" % RMSE_glr_train2)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % RMSE_glr_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE is higher for this second selection of variables for both models. Linear regression is again better than RF. The training part was faster than with all the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(36, {0: 0.0322, 1: 0.067, 2: 0.0015, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 15: 0.0, 17: 0.0034, 18: 0.0026, 19: 0.0, 21: 0.0109, 22: 0.0001, 23: 0.0, 24: 0.0, 26: 0.0003, 27: 0.0011, 28: 0.0003, 29: 0.0, 30: 0.0, 31: 0.0618, 32: 0.176, 33: 0.0152, 34: 0.3189, 35: 0.3087})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractFeatureImp(featureImp, dataset, featuresCol):\n",
    "    list_extract = []\n",
    "    for i in dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"]:\n",
    "        list_extract = list_extract + dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"][i]\n",
    "    varlist = pd.DataFrame(list_extract)\n",
    "    varlist['score'] = varlist['idx'].apply(lambda x: featureImp[x])\n",
    "    return(varlist.sort_values('score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>trip_distance</td>\n",
       "      <td>0.318861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.308683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>tip_amount</td>\n",
       "      <td>0.176001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>RatecodeID_ohe_2</td>\n",
       "      <td>0.067019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>tolls_amount</td>\n",
       "      <td>0.061831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>RatecodeID_ohe_1</td>\n",
       "      <td>0.032221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>speed</td>\n",
       "      <td>0.015163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>21</td>\n",
       "      <td>Borough_PU_ohe_Manhattan</td>\n",
       "      <td>0.010901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>17</td>\n",
       "      <td>payment_type_ohe_1</td>\n",
       "      <td>0.003389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18</td>\n",
       "      <td>payment_type_ohe_2</td>\n",
       "      <td>0.002637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    idx                      name     score\n",
       "3    34             trip_distance  0.318861\n",
       "4    35                  duration  0.308683\n",
       "1    32                tip_amount  0.176001\n",
       "6     1          RatecodeID_ohe_2  0.067019\n",
       "0    31              tolls_amount  0.061831\n",
       "5     0          RatecodeID_ohe_1  0.032221\n",
       "2    33                     speed  0.015163\n",
       "26   21  Borough_PU_ohe_Manhattan  0.010901\n",
       "22   17        payment_type_ohe_1  0.003389\n",
       "23   18        payment_type_ohe_2  0.002637"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExtractFeatureImp(model3.featureImportances, df_model, \"features\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature importances change in comparison with the Random Forest above because we only select some variables. However, trip distance and duration still be the most important variables (it is expected because they have a high correlation with total amount)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing manually parameters of Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxDepth: Maximum depth of the tree. (Nonnegative) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. (default: 5)\n",
      "maxBins: Max number of bins for discretizing continuous features.  Must be at least 2 and at least number of categories for any categorical feature. (default: 32)\n",
      "numTrees: Number of trees to train (at least 1) (default: 20)\n"
     ]
    }
   ],
   "source": [
    "#default parameters for random forest model\n",
    "print(model.explainParam(\"maxDepth\")) #shorter is more generalizable\n",
    "print(model.explainParam(\"maxBins\"))  #more bins more time processing but more exactly\n",
    "print(model.explainParam(\"numTrees\")) #more trees to make the final \"votation\"\n",
    "#maxDepth=5, maxBins=32,numTrees=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr2 = RandomForestRegressor(featuresCol=\"features\",\\\n",
    "                            labelCol=\"label\", numTrees = 10, seed =12, \\\n",
    "                           maxDepth = 10, maxBins = 10)\n",
    "rfr3 = RandomForestRegressor(featuresCol=\"features\",\\\n",
    "                            labelCol=\"label\", numTrees = 10, seed =12, \\\n",
    "                           maxDepth = 5, maxBins = 10)\n",
    "rfr4 = RandomForestRegressor(featuresCol=\"features\",\\\n",
    "                            labelCol=\"label\", numTrees = 10, seed =12, \\\n",
    "                           maxDepth = 10, maxBins = 20)\n",
    "                           \n",
    "model_rfr2 = rfr2.fit(train_data)\n",
    "predictions_rfr_train_2 = model_rfr2.transform(train_data)\n",
    "predictions_rfr_test_2 = model_rfr2.transform(test_data)\n",
    "\n",
    "model_rfr3 = rfr3.fit(train_data)\n",
    "predictions_rfr_train_3 = model_rfr3.transform(train_data)\n",
    "predictions_rfr_test_3 = model_rfr3.transform(test_data)\n",
    "\n",
    "model_rfr4 = rfr4.fit(train_data)\n",
    "predictions_rfr_train_4 = model_rfr4.transform(train_data)\n",
    "predictions_rfr_test_4 = model_rfr4.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N1\n",
      "2.885344558669312\n",
      "2.6563713201039247\n",
      "N2\n",
      "3.543046329107338\n",
      "3.232685066905132\n",
      "N3\n",
      "2.3122678003024904\n",
      "2.178478943270714\n"
     ]
    }
   ],
   "source": [
    "#RMSE\n",
    "print(\"N1\")\n",
    "print( evaluator.evaluate(predictions_rfr_train_2))\n",
    "print(evaluator.evaluate(predictions_rfr_test_2))\n",
    "\n",
    "print(\"N2\")\n",
    "print( evaluator.evaluate(predictions_rfr_train_3))\n",
    "print(evaluator.evaluate(predictions_rfr_test_3))\n",
    "\n",
    "print(\"N3\")\n",
    "print( evaluator.evaluate(predictions_rfr_train_4))\n",
    "print(evaluator.evaluate(predictions_rfr_test_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last Random Forest(RF) is better than the linear regression and the other RF models of the second selection of variables. It could be realised that with only 12 variables the model performance is very similar to one with 21 (first selection of variables), therefore, if we want a faster training and evaluation, it is better to use a simple model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.304888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>trip_distance</td>\n",
       "      <td>0.268635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>tip_amount</td>\n",
       "      <td>0.189494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>tolls_amount</td>\n",
       "      <td>0.090571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>RatecodeID_ohe_2</td>\n",
       "      <td>0.073165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>RatecodeID_ohe_1</td>\n",
       "      <td>0.019647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>speed</td>\n",
       "      <td>0.017491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>21</td>\n",
       "      <td>Borough_PU_ohe_Manhattan</td>\n",
       "      <td>0.015998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>22</td>\n",
       "      <td>Borough_PU_ohe_Queens</td>\n",
       "      <td>0.003867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>RatecodeID_ohe_5</td>\n",
       "      <td>0.003376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    idx                      name     score\n",
       "4    35                  duration  0.304888\n",
       "3    34             trip_distance  0.268635\n",
       "1    32                tip_amount  0.189494\n",
       "0    31              tolls_amount  0.090571\n",
       "6     1          RatecodeID_ohe_2  0.073165\n",
       "5     0          RatecodeID_ohe_1  0.019647\n",
       "2    33                     speed  0.017491\n",
       "26   21  Borough_PU_ohe_Manhattan  0.015998\n",
       "27   22     Borough_PU_ohe_Queens  0.003867\n",
       "7     2          RatecodeID_ohe_5  0.003376"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature importance of the best model above\n",
    "ExtractFeatureImp(model_rfr4.featureImportances, df_model, \"features\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, Grid Search was not used because it takes a long time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion from the models and selection of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Linear regression model had a good performance considering almost all the variables of the data and with few variables (both sets). Therefore, it could be realised that the predictors have a linear relationship with the outcome. Because this type of model is simple than de RF and fast, it is a good option to use with Big Data in this type of escenario (linear relationship). \n",
    "\n",
    "The default Random Forest model perform worse than the linear regresion with all the variables and with few variables. However, after parameter tuning it has a better performance than the linear regression with few variables. Therefore, this model with few variables, is also handy to use when we are working with Big Data. However, we need to tune the parameters and that could take time.\n",
    "\n",
    "Finally, both models have a less RMSE in test data and probably it is because its size. It is only 5% of the total data and therefore it might have less noise (weird cases of trips - outliers) than the train set. Probably the distribution of the data it is not the same. Therefore, the given split affected the performance and for a real case, we need to consider that and may be change the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
